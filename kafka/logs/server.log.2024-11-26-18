[2024-11-26 18:00:04,418] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,422] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,422] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,422] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,422] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,423] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:04,424] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:04,425] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:00:04,425] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:04,426] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:00:04,427] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,427] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,427] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,427] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,427] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:04,428] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:00:04,428] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:04,437] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:00:04,446] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:04,448] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@78b66d36 (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:00:04,451] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:00:04,451] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:00:04,451] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:04,455] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,456] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,457] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,458] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,459] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,459] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,459] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,459] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,459] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,460] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,461] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,462] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,462] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,462] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,462] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,467] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,469] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,469] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,469] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,470] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,471] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:00:04,472] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,472] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,473] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:00:04,473] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:00:04,474] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,474] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,475] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,475] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,475] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,475] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:04,477] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,477] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,478] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:00:04,478] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:00:04,478] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,483] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:00:04,484] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:00:04,485] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:00:04,528] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:00:04,544] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:00:04,545] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:00:04,545] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:04,545] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:04,545] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:00:04,548] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:00:04,576] INFO 39 txns loaded in 15 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:04,576] INFO Snapshot loaded in 31 ms, highest zxid is 0x27, digest is 68253192420 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:04,577] INFO Snapshotting: 0x27 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:04,580] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:04,588] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:00:04,588] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:00:04,604] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:00:04,604] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:00:14,500] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:00:14,643] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:00:14,722] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:00:14,722] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:00:14,741] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:14,750] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,750] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,750] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,750] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,750] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,750] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,751] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,751] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,751] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,751] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,752] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,753] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:14,796] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:00:14,803] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:14,804] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:14,805] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:14,808] INFO Socket connection established, initiating session, client: /127.0.0.1:64842, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:14,813] INFO Creating new log file: log.28 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:00:14,819] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100003621950000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:14,822] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:14,978] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:00:15,021] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:00:15,052] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,053] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,053] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,055] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,089] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:15,110] INFO Recovering 3 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:00:15,140] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-0. (kafka.log.LogLoader)
[2024-11-26 18:00:15,142] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,142] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,142] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,161] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,161] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,161] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,178] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 63ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:15,180] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-1. (kafka.log.LogLoader)
[2024-11-26 18:00:15,181] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,181] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,181] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,185] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,185] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,185] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,187] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:15,190] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-2. (kafka.log.LogLoader)
[2024-11-26 18:00:15,191] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,191] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,191] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,194] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,194] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,194] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:15,197] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:15,200] INFO Loaded 3 logs in 111ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:00:15,202] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:00:15,203] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:00:15,259] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:00:15,270] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:00:15,288] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:00:15,316] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,619] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:00:15,636] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:00:15,640] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,655] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,656] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,656] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,657] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,657] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,674] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:00:15,678] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:00:15,723] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:00:15,742] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100003474560000' does not match current session '0x100003621950000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:00:15,745] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:00:15,748] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:00:15,749] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:00:15,751] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:00:15,760] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:00:15,761] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:00:15,762] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:00:15,762] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:00:15,762] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:00:15,762] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:00:15,764] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:00:15,764] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:00:15,764] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:00:15,764] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,766] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,766] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,767] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,768] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,768] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,768] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:15,777] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:00:15,779] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:00:15,779] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:00:15,780] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:00:15,781] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,781] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,781] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,782] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:00:15,782] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,782] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,782] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:15,782] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:00:15,783] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:00:15,784] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:00:15,785] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:00:15,785] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:00:15,824] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:00:15,828] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:00:15,828] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:00:15,828] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:00:15,829] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:15,945] INFO Session: 0x100003621950000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:15,947] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:15,945] INFO EventThread shut down for session: 0x100003621950000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:15,947] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,949] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,950] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,950] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,950] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:15,950] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:00:15,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:00:15,966] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:00:15,966] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:00:15,969] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:00:15,973] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:00:15,973] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:00:15,973] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:00:15,975] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:00:23,046] INFO Expiring session 0x100003474560000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,071] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,073] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,073] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,073] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,073] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,074] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:35,075] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:35,075] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:00:35,075] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:35,076] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:00:35,076] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,077] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,077] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,077] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,077] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:00:35,077] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:35,078] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:00:35,090] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:00:35,094] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:00:35,097] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:00:35,098] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:00:35,098] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:35,099] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:00:35,103] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,103] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,103] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,103] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,103] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,104] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,104] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,104] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,104] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,104] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,106] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,106] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,107] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,107] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,107] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,107] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,113] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,115] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,116] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:00:35,117] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,117] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,118] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:00:35,118] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:00:35,119] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,119] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,120] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,120] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,120] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,120] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:00:35,122] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,122] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,123] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:00:35,123] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:00:35,123] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,127] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:00:35,128] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:00:35,130] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:00:35,169] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:00:35,183] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:00:35,183] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:00:35,184] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:35,184] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:35,184] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:00:35,190] INFO The digest in the snapshot has digest version of 2, with zxid as 0x27, and digest value as 68253192420 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:00:35,214] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:00:35,215] INFO 18 txns loaded in 6 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:35,215] INFO Snapshot loaded in 32 ms, highest zxid is 0x39, digest is 62891097455 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:00:35,215] INFO Snapshotting: 0x39 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:00:35,217] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:00:35,224] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:00:35,224] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:00:35,239] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:00:45,304] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:00:45,452] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:00:45,525] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:00:45,526] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:00:45,542] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:45,545] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,545] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,546] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,546] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,546] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,546] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,547] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,548] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,548] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,548] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,549] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:00:45,588] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:00:45,604] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:45,605] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:45,606] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:45,608] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:64861, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:45,614] INFO Creating new log file: log.3a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:00:45,620] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003699430000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:00:45,622] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:00:45,788] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:00:45,830] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:00:45,859] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:45,860] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:45,860] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:45,862] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:00:45,894] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:45,922] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:00:45,965] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:45,976] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 49ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:45,980] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:45,982] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:45,986] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:00:45,988] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:00:45,990] INFO Loaded 3 logs in 95ms (kafka.log.LogManager)
[2024-11-26 18:00:45,991] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:00:45,992] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:00:46,047] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:00:46,072] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:00:46,087] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:00:46,133] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:46,428] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:00:46,446] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:00:46,453] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:46,469] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,469] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,469] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,471] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,471] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,488] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:00:46,488] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:00:46,542] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:00:46,562] INFO Stat of the created znode at /brokers/ids/0 is: 73,73,1732618846552,1732618846552,1,0,0,72057828537466880,214,0,73
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:00:46,563] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 73 (kafka.zk.KafkaZkClient)
[2024-11-26 18:00:46,611] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,619] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,620] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,635] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:00:46,639] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:00:46,658] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:00:46,667] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:00:46,672] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:00:46,730] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:00:46,773] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:00:46,800] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:00:46,802] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:00:46,804] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:00:46,804] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:00:46,804] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:00:46,804] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:00:46,809] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:00:46,809] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:00:46,810] INFO Kafka startTimeMs: 1732618846804 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:00:46,811] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:00:47,312] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-0, data-real-time-1, data-real-time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:00:47,328] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:47,352] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:00:47,352] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:00:47,371] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:00:47,380] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:01:02,393] INFO Creating topic data_real_time with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2024-11-26 18:01:02,428] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:01:02,442] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:01:02,444] INFO Created log for partition data_real_time-0 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:01:02,445] INFO [Partition data_real_time-0 broker=0] No checkpointed highwatermark is found for partition data_real_time-0 (kafka.cluster.Partition)
[2024-11-26 18:01:02,446] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:01:10,102] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:11,106] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:12,120] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:13,136] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:14,149] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:15,098] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:16,167] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:17,178] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:18,193] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:19,194] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:20,112] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:21,219] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:22,229] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:23,244] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:24,245] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:25,122] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:26,261] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:27,263] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:28,273] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:29,279] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:30,129] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:31,291] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:32,292] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:33,307] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:34,321] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:35,131] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:36,335] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:37,351] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:38,351] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:39,366] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:40,130] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:41,379] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:42,391] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:43,391] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:44,405] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:45,142] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:46,424] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:47,438] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:48,451] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:49,455] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:50,165] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:51,468] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:52,481] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:53,490] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:54,504] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:55,172] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:56,525] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:57,539] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:58,553] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:01:59,563] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:00,187] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:01,568] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:02,581] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:03,596] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:04,609] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:05,199] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:06,633] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:07,636] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:08,645] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:09,659] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:10,660] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:11,676] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:12,689] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:13,700] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:14,705] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:15,218] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:15,719] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:16,733] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:17,736] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:18,749] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:19,755] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:20,771] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:21,780] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:22,793] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:23,803] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:24,814] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:25,826] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:02:26,136] WARN Session 0x100003699430000 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:05:46,197] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,199] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,199] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,200] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,200] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,201] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:05:46,201] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:05:46,202] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:05:46,202] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:05:46,203] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:05:46,204] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,204] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,204] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,204] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,204] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:05:46,204] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:05:46,206] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:05:46,215] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:05:46,223] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:05:46,224] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:05:46,226] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:05:46,226] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:05:46,226] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:05:46,231] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,231] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,231] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,231] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,232] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,234] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,236] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,237] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,239] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:05:46,239] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,240] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,240] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:05:46,241] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:05:46,241] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,241] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,242] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,242] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,242] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,242] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:05:46,243] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,244] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,244] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:05:46,244] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:05:46,244] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,256] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:05:46,257] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:05:46,258] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:05:46,298] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:05:46,315] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:05:46,317] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:05:46,320] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:05:46,321] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:05:46,321] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:05:46,329] INFO The digest in the snapshot has digest version of 2, with zxid as 0x39, and digest value as 62891097455 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:05:46,356] INFO 28 txns loaded in 9 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:05:46,356] INFO Snapshot loaded in 35 ms, highest zxid is 0x55, digest is 75533119827 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:05:46,357] INFO Snapshotting: 0x55 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:05:46,361] INFO Snapshot taken in 4 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:05:46,367] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:05:46,368] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:05:46,382] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:05:46,383] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:05:51,539] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:05:51,685] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:05:51,756] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:05:51,757] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:05:51,773] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:51,777] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,777] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,777] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,777] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,777] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,777] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,778] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,778] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,778] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,778] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,779] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,780] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:51,818] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:05:51,824] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:51,826] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:51,828] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:51,829] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:65391, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:51,835] INFO Creating new log file: log.56 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:05:51,842] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003b58aa0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:51,845] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:51,987] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:05:52,032] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:05:52,060] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:52,061] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:52,061] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:52,062] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:52,097] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:52,127] INFO Recovering 4 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:05:52,160] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-0. (kafka.log.LogLoader)
[2024-11-26 18:05:52,161] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,162] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,162] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,182] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,184] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,184] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,195] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 62ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:52,197] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-1. (kafka.log.LogLoader)
[2024-11-26 18:05:52,197] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,198] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,198] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,202] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,202] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,202] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,203] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:52,206] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-2. (kafka.log.LogLoader)
[2024-11-26 18:05:52,206] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,206] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,206] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,210] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,212] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,212] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,214] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 10ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:52,227] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:05:52,227] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,227] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,227] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,240] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 37 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:05:52,243] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,244] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,244] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:05:52,253] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:52,264] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 49ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:52,267] INFO Loaded 4 logs in 170ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:05:52,269] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:05:52,270] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:05:52,326] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:52,344] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:52,369] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:05:52,396] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,669] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:05:52,690] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:05:52,694] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,710] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,710] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,712] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,712] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,712] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,732] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:52,733] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:52,782] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:05:52,800] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100003699430000' does not match current session '0x100003b58aa0000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:05:52,804] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:52,807] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:05:52,809] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:05:52,811] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:52,818] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:05:52,820] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:05:52,820] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:52,820] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:52,820] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:52,821] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:05:52,822] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:05:52,822] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:05:52,822] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:05:52,822] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,823] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,823] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,824] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,825] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,825] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,825] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,825] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,825] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,826] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:52,837] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:52,837] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:52,837] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:52,838] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:05:52,839] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,839] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,840] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,841] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:05:52,843] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,843] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,843] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:52,843] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:05:52,844] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:05:52,845] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:52,846] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:52,846] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:52,889] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:05:52,892] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:52,893] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:52,893] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:52,894] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:53,000] INFO Session: 0x100003b58aa0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:53,000] INFO EventThread shut down for session: 0x100003b58aa0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:53,002] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:53,002] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,003] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,003] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,003] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,003] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,003] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:53,004] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:05:53,021] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:05:53,021] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:05:53,021] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:05:53,023] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:05:53,026] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:05:53,027] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:05:53,027] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:53,028] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:05:56,064] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:05:56,211] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:05:56,282] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:05:56,283] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:05:56,300] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:56,304] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,304] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,304] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,304] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,304] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,304] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,306] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,307] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,307] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,307] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,308] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:56,344] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:05:56,349] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:56,351] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:56,353] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:56,355] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:65399, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:56,360] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003b58aa0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:56,362] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:56,497] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:05:56,538] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:05:56,567] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:56,567] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:56,568] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:56,569] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:56,598] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:56,621] INFO Skipping recovery of 4 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:05:56,664] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,675] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 46ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:56,678] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,680] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:56,685] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,687] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:56,695] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,695] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,695] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:05:56,700] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:05:56,703] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 15ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:05:56,705] INFO Loaded 4 logs in 106ms (kafka.log.LogManager)
[2024-11-26 18:05:56,708] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:05:56,708] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:05:56,759] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:56,771] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:56,794] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:05:56,820] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,151] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:05:57,175] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:05:57,221] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,297] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,311] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,310] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,330] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,332] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:57,330] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:05:57,329] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,384] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100003699430000' does not match current session '0x100003b58aa0001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:05:57,331] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:57,396] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:57,401] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:05:57,403] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:05:57,416] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:57,422] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:05:57,439] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:05:57,442] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:57,442] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:57,442] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:05:57,443] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:05:57,444] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:05:57,444] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:05:57,445] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:05:57,446] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,446] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,446] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,450] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,450] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,450] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,451] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,452] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,452] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,452] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,453] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,453] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,453] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,454] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,454] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:05:57,459] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:57,460] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:57,460] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:05:57,461] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:05:57,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,461] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:05:57,463] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,463] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,463] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:05:57,463] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:05:57,464] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:05:57,464] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:57,466] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:57,466] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:05:57,519] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:05:57,521] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:57,521] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:57,521] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:05:57,522] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:57,636] INFO Session: 0x100003b58aa0001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:05:57,636] INFO EventThread shut down for session: 0x100003b58aa0001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:05:57,637] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:05:57,637] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,639] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,639] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,640] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,642] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,642] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,645] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,646] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,646] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,646] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,646] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,646] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:05:57,647] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:05:57,661] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:05:57,663] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:05:57,663] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:05:57,667] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:05:57,673] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:05:57,674] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:05:57,674] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:05:57,675] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:06:05,040] INFO Expiring session 0x100003699430000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:06:07,362] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:06:07,506] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:06:07,575] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:06:07,576] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:06:07,592] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:06:07,595] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,595] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,595] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,595] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,595] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,595] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,596] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,596] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,596] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,597] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,599] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:06:07,634] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:06:07,642] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:06:07,644] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:06:07,645] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:06:07,647] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:65429, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:06:07,652] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003b58aa0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:06:07,655] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:06:07,791] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:06:07,833] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:06:07,862] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:06:07,862] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:06:07,863] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:06:07,865] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:06:07,898] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:06:07,920] INFO Skipping recovery of 4 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:06:07,961] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:07,972] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 47ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:06:07,975] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:07,976] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:06:07,978] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:07,980] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:06:07,990] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:07,990] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:07,990] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:06:07,996] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:06:08,000] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 18ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:06:08,003] INFO Loaded 4 logs in 104ms (kafka.log.LogManager)
[2024-11-26 18:06:08,005] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:06:08,006] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:06:08,057] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:06:08,069] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:06:08,092] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:06:08,120] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:06:08,407] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:06:08,423] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:06:08,427] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:06:08,443] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,444] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,444] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,448] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,449] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,466] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:06:08,467] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:06:08,514] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:06:08,529] INFO Stat of the created znode at /brokers/ids/0 is: 136,136,1732619168522,1732619168522,1,0,0,72057848928534530,214,0,136
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:06:08,529] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 136 (kafka.zk.KafkaZkClient)
[2024-11-26 18:06:08,571] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,592] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,592] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,604] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:06:08,610] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:06:08,635] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:06:08,638] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:06:08,640] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:06:08,706] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:06:08,729] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:06:08,751] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:06:08,753] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:06:08,755] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:06:08,755] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:06:08,755] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:06:08,756] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:06:08,759] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:06:08,759] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:06:08,759] INFO Kafka startTimeMs: 1732619168756 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:06:08,760] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:06:09,224] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:06:09,241] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data-real-time-0, data-real-time-1, data-real-time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:06:09,258] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 35 (kafka.cluster.Partition)
[2024-11-26 18:06:09,267] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:06:09,273] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:06:09,275] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:06:09,304] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:06:24,777] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:06:24,831] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:06:24,831] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:06:24,840] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:06:24,841] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:06:24,848] WARN Failed atomic move of D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 to D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.09782d1d96f34fa1ac0fde10b1f9a4ba-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.09782d1d96f34fa1ac0fde10b1f9a4ba-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:06:24,849] ERROR Error while renaming dir for data-real-time-2 in log dir D:\GR1\kafka\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.09782d1d96f34fa1ac0fde10b1f9a4ba-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:414)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
	Suppressed: java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.09782d1d96f34fa1ac0fde10b1f9a4ba-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1430)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2024-11-26 18:06:24,851] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\GR1\kafka\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-11-26 18:06:24,865] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:06:24,866] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:06:24,869] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions data_real_time-0 and stopped moving logs for partitions  because they are in the failed log directory D:\GR1\kafka\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2024-11-26 18:06:24,869] WARN Stopping serving logs in dir D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:06:24,872] ERROR Shutdown broker because all log dirs in D:\GR1\kafka\tmp\kafka-logs have failed (kafka.log.LogManager)
[2024-11-26 18:06:25,359] WARN Close of session 0x100003b58aa0002 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:06:43,041] INFO Expiring session 0x100003b58aa0002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,847] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,850] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,850] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,850] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,850] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,852] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:07:16,852] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:07:16,852] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:07:16,852] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:07:16,853] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:07:16,853] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,854] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,854] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,854] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,854] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:07:16,854] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:07:16,854] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:07:16,865] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:07:16,873] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:07:16,876] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:07:16,877] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:07:16,877] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:07:16,878] INFO Removing file: Nov 26, 2024, 5:58:14PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:07:16,879] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:07:16,883] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,884] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,887] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,894] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,895] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,896] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,897] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:07:16,899] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,900] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,901] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:07:16,901] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:07:16,902] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,902] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,903] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,903] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,903] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,903] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:07:16,905] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,905] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,905] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:07:16,905] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:07:16,905] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:16,912] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:07:16,913] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:07:16,914] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:07:16,952] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:07:16,968] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:07:16,969] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:07:16,969] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:07:16,969] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:07:16,970] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:07:16,976] INFO The digest in the snapshot has digest version of 2, with zxid as 0x55, and digest value as 75533119827 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:07:17,001] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:07:17,004] INFO 61 txns loaded in 11 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:07:17,004] INFO Snapshot loaded in 36 ms, highest zxid is 0x92, digest is 73360588826 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:07:17,006] INFO Snapshotting: 0x92 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.92 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:07:17,009] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:07:17,015] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:07:17,015] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:07:17,031] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:07:24,436] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:07:24,580] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:07:24,649] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:07:24,650] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:07:24,666] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:24,669] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,669] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,669] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,669] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,669] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,669] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,670] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,671] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,672] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,672] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,672] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,673] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:24,709] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:07:24,715] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:24,717] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:24,717] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:24,720] INFO Socket connection established, initiating session, client: /127.0.0.1:49219, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:24,724] INFO Creating new log file: log.93 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:07:24,731] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100003cbac20000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:24,733] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:24,878] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:07:24,920] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:07:24,946] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:24,946] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:24,947] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:24,948] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:24,981] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:25,008] INFO Recovering 4 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:07:25,042] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-0. (kafka.log.LogLoader)
[2024-11-26 18:07:25,043] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,044] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,044] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,069] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,070] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,070] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,082] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 68ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:25,086] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-1. (kafka.log.LogLoader)
[2024-11-26 18:07:25,086] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,086] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,086] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,088] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,088] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,088] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,090] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:25,092] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-2. (kafka.log.LogLoader)
[2024-11-26 18:07:25,093] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,093] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,093] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,097] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,097] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,097] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,099] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:25,103] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:07:25,103] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,104] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,104] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:07:25,104] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,116] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 37 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:07:25,120] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,120] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,120] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:07:25,122] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:25,123] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 23ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:25,127] INFO Loaded 4 logs in 145ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:07:25,129] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:07:25,129] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:07:25,182] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:07:25,197] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:07:25,216] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:07:25,239] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:25,509] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:07:25,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:07:25,527] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:25,544] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,549] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,549] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,549] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,549] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,564] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:07:25,565] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:07:25,617] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:07:25,637] INFO Stat of the created znode at /brokers/ids/0 is: 162,162,1732619245628,1732619245628,1,0,0,72057854869241856,214,0,162
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:07:25,637] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 162 (kafka.zk.KafkaZkClient)
[2024-11-26 18:07:25,676] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,682] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,682] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,696] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:07:25,700] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:07:25,743] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:07:25,749] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:07:25,749] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:07:25,823] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:25,845] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:07:25,877] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:07:25,879] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:07:25,884] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:07:25,884] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:07:25,885] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:07:25,885] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:07:25,888] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:07:25,889] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:07:25,889] INFO Kafka startTimeMs: 1732619245885 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:07:25,893] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:07:26,362] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:26,372] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:26,394] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 37 (kafka.cluster.Partition)
[2024-11-26 18:07:26,416] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:26,423] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:07:26,428] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:07:26,430] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:07:26,507] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:07:26,513] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:07:26,519] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:26,519] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:07:26,536] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:26,539] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:07:26,548] WARN Failed atomic move of D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 to D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.72bdc87662654d408d06881f3d34cd4d-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.72bdc87662654d408d06881f3d34cd4d-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:07:26,551] ERROR Error while renaming dir for data-real-time-2 in log dir D:\GR1\kafka\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.72bdc87662654d408d06881f3d34cd4d-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:414)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
	Suppressed: java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.72bdc87662654d408d06881f3d34cd4d-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1430)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2024-11-26 18:07:26,552] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\GR1\kafka\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-11-26 18:07:26,563] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:26,563] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:07:26,565] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions data_real_time-0 and stopped moving logs for partitions  because they are in the failed log directory D:\GR1\kafka\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2024-11-26 18:07:26,566] WARN Stopping serving logs in dir D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:07:26,570] ERROR Shutdown broker because all log dirs in D:\GR1\kafka\tmp\kafka-logs have failed (kafka.log.LogManager)
[2024-11-26 18:07:27,079] WARN Close of session 0x100003cbac20000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:07:37,339] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:07:37,493] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:07:37,570] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:07:37,570] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:07:37,587] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:37,590] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,590] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,591] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,591] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,591] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,591] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,592] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,593] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,593] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,593] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,593] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,593] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,595] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:37,634] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:07:37,640] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:37,641] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:37,643] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:37,644] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:49251, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:37,651] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003cbac20001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:37,653] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:37,809] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:07:37,863] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:07:37,891] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:37,891] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:37,891] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:37,893] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:37,929] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:37,950] INFO Recovering 4 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:07:37,984] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-0. (kafka.log.LogLoader)
[2024-11-26 18:07:37,985] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:37,986] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:37,986] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,006] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,006] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,006] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,018] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 60ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:38,022] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-1. (kafka.log.LogLoader)
[2024-11-26 18:07:38,022] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,022] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,023] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,025] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,025] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,025] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,027] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:38,030] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-2. (kafka.log.LogLoader)
[2024-11-26 18:07:38,030] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,031] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,031] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,033] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,033] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,034] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,036] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 9ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:38,041] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:07:38,042] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,042] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,042] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:07:38,043] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,060] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 37 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:07:38,063] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,063] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,064] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:07:38,066] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:07:38,068] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 32ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:07:38,071] INFO Loaded 4 logs in 140ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:07:38,073] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:07:38,074] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:07:38,136] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:07:38,155] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:07:38,182] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:07:38,213] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,474] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:07:38,491] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:07:38,496] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,513] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,514] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,514] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,515] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,516] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,530] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:07:38,531] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:07:38,584] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:07:38,598] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100003cbac20000' does not match current session '0x100003cbac20001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:07:38,602] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:07:38,604] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:07:38,604] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:07:38,606] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:07:38,612] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:07:38,614] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:07:38,615] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:07:38,615] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:07:38,615] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:07:38,615] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:38,616] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:07:38,616] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:07:38,617] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:07:38,617] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,617] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,617] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,618] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,618] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,618] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,619] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,621] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,621] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,621] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:07:38,627] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:07:38,628] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:07:38,628] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:07:38,629] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:07:38,629] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,629] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,630] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,631] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:07:38,635] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,636] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,636] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:07:38,637] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:07:38,638] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:07:38,639] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:07:38,640] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:07:38,640] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:07:38,683] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:07:38,686] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:07:38,686] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:07:38,686] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:07:38,687] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:38,794] INFO Session: 0x100003cbac20001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:07:38,794] INFO EventThread shut down for session: 0x100003cbac20001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:07:38,795] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:07:38,795] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,797] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,797] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,797] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,797] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,797] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,798] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,798] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,798] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,798] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,799] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,799] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:07:38,799] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:07:38,819] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:07:38,822] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:07:38,822] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:07:38,826] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:07:38,832] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:07:38,832] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:07:38,833] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:07:38,834] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:07:45,055] INFO Expiring session 0x100003cbac20000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,841] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,844] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,844] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,844] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,844] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,845] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:08:02,845] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:08:02,845] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:08:02,846] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:08:02,846] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:08:02,847] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,847] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,847] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,848] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,848] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:08:02,848] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:08:02,848] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:08:02,858] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:08:02,866] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:08:02,869] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:08:02,870] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:08:02,870] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:08:02,871] INFO Removing file: Nov 26, 2024, 5:59:32PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.1 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:08:02,872] INFO Removing file: Nov 26, 2024, 6:00:04PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:08:02,873] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:08:02,875] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,877] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,877] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,878] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,881] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,882] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,882] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,882] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,882] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,882] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,888] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,889] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,890] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,891] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:08:02,893] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,894] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,895] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:08:02,895] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,896] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:08:02,898] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,898] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,898] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:08:02,898] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:08:02,898] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:02,905] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:08:02,906] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:08:02,907] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:08:02,946] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:08:02,959] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:08:02,959] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:08:02,961] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:08:02,961] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:08:02,962] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.92 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:08:02,966] INFO The digest in the snapshot has digest version of 2, with zxid as 0x92, and digest value as 73360588826 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:08:02,996] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:08:02,996] INFO 40 txns loaded in 8 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:08:02,996] INFO Snapshot loaded in 35 ms, highest zxid is 0xba, digest is 77535771716 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:08:02,998] INFO Snapshotting: 0xba to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.ba (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:08:03,000] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:08:03,006] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:08:03,007] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:08:03,021] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:08:10,722] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:08:10,866] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:08:10,941] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:08:10,942] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:08:10,958] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:08:10,961] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,961] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,962] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,962] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,962] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,962] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,962] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,963] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,964] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:10,965] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:08:11,002] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:08:11,009] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:08:11,011] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:08:11,012] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:08:11,014] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:49315, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:08:11,019] INFO Creating new log file: log.bb (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:08:11,027] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003d6e690000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:08:11,030] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:08:11,209] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:08:11,256] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:08:11,288] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:08:11,288] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:08:11,288] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:08:11,290] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:08:11,325] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:08:11,347] INFO Skipping recovery of 4 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:08:11,398] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,410] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 57ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:08:11,413] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,414] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:08:11,417] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,420] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:08:11,430] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 37 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,430] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,430] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=37, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000037.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:08:11,437] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 37 (kafka.log.UnifiedLog$)
[2024-11-26 18:08:11,440] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=37) with 1 segments, local-log-start-offset 0 and log-end-offset 37 in 19ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:08:11,442] INFO Loaded 4 logs in 117ms (kafka.log.LogManager)
[2024-11-26 18:08:11,445] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:08:11,446] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:08:11,513] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:08:11,539] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:08:11,562] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:08:11,605] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:08:11,923] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:08:11,941] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:08:11,947] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:08:11,964] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:11,965] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:11,965] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:11,974] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:11,974] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:11,989] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:08:11,989] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:08:12,038] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:08:12,057] INFO Stat of the created znode at /brokers/ids/0 is: 202,202,1732619292048,1732619292048,1,0,0,72057857883308032,214,0,202
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:08:12,057] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 202 (kafka.zk.KafkaZkClient)
[2024-11-26 18:08:12,098] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:12,111] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:12,111] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:12,131] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:08:12,135] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:08:12,164] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:08:12,171] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:08:12,173] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:08:12,245] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:08:12,270] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:08:12,296] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:08:12,299] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:08:12,303] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:08:12,303] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:08:12,304] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:08:12,304] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:08:12,308] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:08:12,308] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:08:12,314] INFO Kafka startTimeMs: 1732619292304 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:08:12,319] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:08:12,788] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:08:12,800] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 37 (kafka.cluster.Partition)
[2024-11-26 18:08:12,812] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:08:12,812] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:08:12,812] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:08:12,833] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:08:12,837] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:08:12,844] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:08:12,847] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:08:12,848] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:08:12,844] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:08:12,857] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:08:12,860] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:08:12,866] WARN Failed atomic move of D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 to D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f42104eccee44a918b4237fec9e347e9-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f42104eccee44a918b4237fec9e347e9-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:08:12,869] ERROR Error while renaming dir for data-real-time-2 in log dir D:\GR1\kafka\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f42104eccee44a918b4237fec9e347e9-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:414)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
	Suppressed: java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f42104eccee44a918b4237fec9e347e9-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1430)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2024-11-26 18:08:12,873] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\GR1\kafka\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-11-26 18:08:12,893] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:08:12,923] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:08:12,927] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions data_real_time-0 and stopped moving logs for partitions  because they are in the failed log directory D:\GR1\kafka\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2024-11-26 18:08:12,927] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:08:12,927] WARN Stopping serving logs in dir D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:08:12,927] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:08:12,929] ERROR Shutdown broker because all log dirs in D:\GR1\kafka\tmp\kafka-logs have failed (kafka.log.LogManager)
[2024-11-26 18:08:13,418] WARN Close of session 0x100003d6e690000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:08:31,051] INFO Expiring session 0x100003d6e690000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,580] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,583] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,583] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,583] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,583] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,585] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:09:22,585] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:09:22,586] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:09:22,586] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:09:22,587] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:09:22,587] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,587] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,587] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,587] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,587] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:09:22,587] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:09:22,588] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:09:22,596] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:09:22,603] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:09:22,606] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:09:22,606] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:09:22,606] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:09:22,607] INFO Removing file: Nov 26, 2024, 6:00:23PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.28 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:09:22,607] INFO Removing file: Nov 26, 2024, 6:00:35PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:09:22,608] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:09:22,612] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,612] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,612] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,612] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,612] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,612] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,614] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,614] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,614] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,614] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,615] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,616] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,616] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,616] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,616] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,617] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,624] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,624] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,624] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,625] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,626] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,626] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,626] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,626] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,626] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,627] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,628] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:09:22,629] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,629] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,630] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:09:22,630] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,631] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:09:22,633] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,633] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,635] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:09:22,635] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:09:22,635] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,641] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:09:22,642] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:09:22,644] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:09:22,680] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:09:22,696] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:09:22,696] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:09:22,696] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:09:22,696] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:09:22,697] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.ba (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:09:22,703] INFO The digest in the snapshot has digest version of 2, with zxid as 0xba, and digest value as 77535771716 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:09:22,730] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:09:22,730] INFO 25 txns loaded in 8 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:09:22,730] INFO Snapshot loaded in 34 ms, highest zxid is 0xd3, digest is 76489585118 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:09:22,731] INFO Snapshotting: 0xd3 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.d3 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:09:22,733] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:09:22,739] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:09:22,739] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:09:22,756] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:09:29,039] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:09:29,177] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:09:29,258] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:09:29,258] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:09:29,273] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:09:29,278] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,278] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,278] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,278] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,278] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,279] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,279] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,280] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,281] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,281] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,281] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,281] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,283] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:09:29,319] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:09:29,326] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:09:29,327] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:09:29,328] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:09:29,330] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:49381, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:09:29,336] INFO Creating new log file: log.d4 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:09:29,343] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003ea5de0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:09:29,345] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:09:29,485] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:09:29,526] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:09:29,552] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:09:29,552] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:09:29,553] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:09:29,554] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:09:29,557] INFO [KafkaServer id=0] Rewriting D:/GR1/kafka/tmp/kafka-logs\meta.properties (kafka.server.KafkaServer)
[2024-11-26 18:09:29,638] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:09:29,642] INFO No logs found to be loaded in D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:09:29,649] INFO Loaded 0 logs in 12ms (kafka.log.LogManager)
[2024-11-26 18:09:29,651] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:09:29,651] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:09:29,702] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:09:29,711] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:09:29,723] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:09:29,740] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:09:30,005] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:09:30,032] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:09:30,040] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:09:30,070] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,070] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,070] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,070] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,070] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,085] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:09:30,085] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:09:30,125] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:09:30,139] INFO Stat of the created znode at /brokers/ids/0 is: 227,227,1732619370134,1732619370134,1,0,0,72057863108689920,214,0,227
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:09:30,141] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 227 (kafka.zk.KafkaZkClient)
[2024-11-26 18:09:30,189] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,196] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,197] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,216] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:09:30,220] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:09:30,242] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:09:30,245] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:09:30,245] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:09:30,295] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:09:30,362] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:09:30,385] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:09:30,388] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:09:30,392] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:09:30,394] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:09:30,394] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:09:30,394] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:09:30,403] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:09:30,405] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:09:30,405] INFO Kafka startTimeMs: 1732619370394 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:09:30,410] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:09:30,823] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:09:30,834] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:09:30,865] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:09:30,874] INFO Created log for partition data_real_time-0 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:09:30,876] INFO [Partition data_real_time-0 broker=0] No checkpointed highwatermark is found for partition data_real_time-0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,877] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,889] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:09:30,890] INFO Created log for partition data-real-time-0 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:09:30,891] INFO [Partition data-real-time-0 broker=0] No checkpointed highwatermark is found for partition data-real-time-0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,891] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,894] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:09:30,895] INFO Created log for partition data-real-time-1 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-1 with properties {} (kafka.log.LogManager)
[2024-11-26 18:09:30,895] INFO [Partition data-real-time-1 broker=0] No checkpointed highwatermark is found for partition data-real-time-1 (kafka.cluster.Partition)
[2024-11-26 18:09:30,896] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,900] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:09:30,901] INFO Created log for partition data-real-time-2 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 with properties {} (kafka.log.LogManager)
[2024-11-26 18:09:30,901] INFO [Partition data-real-time-2 broker=0] No checkpointed highwatermark is found for partition data-real-time-2 (kafka.cluster.Partition)
[2024-11-26 18:09:30,901] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:09:30,912] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:09:30,918] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:09:30,920] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:09:30,923] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:09:30,924] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:09:30,927] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:09:30,928] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:09:30,933] WARN Failed atomic move of D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 to D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.5dba6d5dd1f04ab1a249859bc8b06202-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.5dba6d5dd1f04ab1a249859bc8b06202-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:09:30,934] ERROR Error while renaming dir for data-real-time-2 in log dir D:\GR1\kafka\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.5dba6d5dd1f04ab1a249859bc8b06202-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:414)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
	Suppressed: java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.5dba6d5dd1f04ab1a249859bc8b06202-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1430)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2024-11-26 18:09:30,937] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\GR1\kafka\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-11-26 18:09:30,946] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:09:30,946] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:09:30,948] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions data_real_time-0 and stopped moving logs for partitions  because they are in the failed log directory D:\GR1\kafka\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2024-11-26 18:09:30,948] WARN Stopping serving logs in dir D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:09:30,954] ERROR Shutdown broker because all log dirs in D:\GR1\kafka\tmp\kafka-logs have failed (kafka.log.LogManager)
[2024-11-26 18:09:31,452] WARN Close of session 0x100003ea5de0000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:09:49,047] INFO Expiring session 0x100003ea5de0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,334] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,337] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,337] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,337] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,337] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,338] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:10:06,339] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:10:06,339] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:10:06,339] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:10:06,340] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:10:06,341] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,342] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,342] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,342] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,342] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:10:06,342] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:10:06,343] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:10:06,353] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:10:06,362] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:10:06,368] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:10:06,369] INFO Removing file: Nov 26, 2024, 6:01:56PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.3a (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:10:06,369] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:10:06,369] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:10:06,370] INFO Removing file: Nov 26, 2024, 6:05:46PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.55 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:10:06,371] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:10:06,377] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,378] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,379] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,379] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,379] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,379] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,379] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,380] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,380] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,380] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,382] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,382] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,382] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,382] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,382] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,383] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,390] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,391] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,392] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,393] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:10:06,393] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,394] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,395] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:10:06,395] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,396] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:10:06,399] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,399] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,399] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:10:06,399] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:10:06,399] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,406] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:10:06,407] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:10:06,409] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:10:06,476] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:10:06,506] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:10:06,507] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:10:06,508] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:10:06,508] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:10:06,509] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.d3 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:10:06,513] INFO The digest in the snapshot has digest version of 2, with zxid as 0xd3, and digest value as 76489585118 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:10:06,542] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:10:06,543] INFO 25 txns loaded in 8 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:10:06,543] INFO Snapshot loaded in 33 ms, highest zxid is 0xec, digest is 75330525581 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:10:06,544] INFO Snapshotting: 0xec to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.ec (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:10:06,550] INFO Snapshot taken in 5 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:10:06,558] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:10:06,559] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:10:06,573] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:10:17,930] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:10:18,087] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:10:18,172] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:10:18,173] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:10:18,189] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:18,193] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,194] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,194] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,194] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,194] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,194] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,195] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,195] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,195] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,196] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,198] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:18,232] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:10:18,240] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:18,241] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:18,242] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:18,244] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:49710, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:18,249] INFO Creating new log file: log.ed (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:10:18,257] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003f51070000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:18,260] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:18,404] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:10:18,447] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:10:18,474] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:18,474] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:18,475] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:18,476] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:18,480] INFO [KafkaServer id=0] Rewriting D:/GR1/kafka/tmp/kafka-logs\meta.properties (kafka.server.KafkaServer)
[2024-11-26 18:10:18,559] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:18,564] INFO No logs found to be loaded in D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:10:18,572] INFO Loaded 0 logs in 12ms (kafka.log.LogManager)
[2024-11-26 18:10:18,573] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:10:18,573] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:10:18,628] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:10:18,636] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:10:18,649] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:10:18,665] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:18,962] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:10:18,995] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:10:19,001] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:19,017] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,017] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,018] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,018] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,018] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,029] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:10:19,029] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:10:19,065] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:10:19,080] INFO Stat of the created znode at /brokers/ids/0 is: 252,252,1732619419074,1732619419074,1,0,0,72057865980280832,214,0,252
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:10:19,081] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 252 (kafka.zk.KafkaZkClient)
[2024-11-26 18:10:19,122] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,132] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,132] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,154] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:10:19,159] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:10:19,181] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:10:19,183] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:10:19,184] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:10:19,230] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:19,293] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:10:19,331] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:10:19,335] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:10:19,337] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:10:19,338] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:10:19,338] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:10:19,339] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:10:19,346] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:10:19,347] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:10:19,347] INFO Kafka startTimeMs: 1732619419339 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:10:19,353] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:10:19,771] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:19,771] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:19,778] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:19,836] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:19,845] INFO Created log for partition data_real_time-0 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:10:19,847] INFO [Partition data_real_time-0 broker=0] No checkpointed highwatermark is found for partition data_real_time-0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,848] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,860] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:19,861] INFO Created log for partition data-real-time-0 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:10:19,862] INFO [Partition data-real-time-0 broker=0] No checkpointed highwatermark is found for partition data-real-time-0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,862] INFO [Partition data-real-time-0 broker=0] Log loaded for partition data-real-time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,866] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:19,866] INFO Created log for partition data-real-time-1 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-1 with properties {} (kafka.log.LogManager)
[2024-11-26 18:10:19,867] INFO [Partition data-real-time-1 broker=0] No checkpointed highwatermark is found for partition data-real-time-1 (kafka.cluster.Partition)
[2024-11-26 18:10:19,867] INFO [Partition data-real-time-1 broker=0] Log loaded for partition data-real-time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,871] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:19,871] INFO Created log for partition data-real-time-2 in D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 with properties {} (kafka.log.LogManager)
[2024-11-26 18:10:19,872] INFO [Partition data-real-time-2 broker=0] No checkpointed highwatermark is found for partition data-real-time-2 (kafka.cluster.Partition)
[2024-11-26 18:10:19,872] INFO [Partition data-real-time-2 broker=0] Log loaded for partition data-real-time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:10:19,887] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:10:19,888] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: data-real-time-2, data-real-time-1, data-real-time-0. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:10:19,891] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:19,892] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:19,895] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:19,895] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:19,901] WARN Failed atomic move of D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 to D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f7f36c5015024d948418bc3122954824-delete retrying with a non-atomic move (org.apache.kafka.common.utils.Utils)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f7f36c5015024d948418bc3122954824-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:10:19,902] ERROR Error while renaming dir for data-real-time-2 in log dir D:\GR1\kafka\tmp\kafka-logs (org.apache.kafka.storage.internals.log.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f7f36c5015024d948418bc3122954824-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:414)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
	at java.base/java.nio.file.Files.move(Files.java:1430)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:959)
	at kafka.log.LocalLog.$anonfun$renameDir$2(LocalLog.scala:113)
	at kafka.log.LocalLog.renameDir(LocalLog.scala:716)
	at kafka.log.UnifiedLog.$anonfun$renameDir$2(UnifiedLog.scala:683)
	at kafka.log.UnifiedLog.renameDir(UnifiedLog.scala:1951)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1322)
	at kafka.log.LogManager.$anonfun$asyncDelete$4(LogManager.scala:1359)
	at scala.Option.foreach(Option.scala:437)
	at kafka.log.LogManager.$anonfun$asyncDelete$3(LogManager.scala:1357)
	at kafka.log.LogManager.$anonfun$asyncDelete$3$adapted(LogManager.scala:1355)
	at scala.collection.mutable.HashSet$Node.foreach(HashSet.scala:450)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:376)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:1355)
	at kafka.server.ReplicaManager.stopPartitions(ReplicaManager.scala:616)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:551)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:335)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:194)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:159)
	at java.base/java.lang.Thread.run(Thread.java:1570)
	Suppressed: java.nio.file.AccessDeniedException: D:\GR1\kafka\tmp\kafka-logs\data-real-time-2 -> D:\GR1\kafka\tmp\kafka-logs\data-real-time-2.f7f36c5015024d948418bc3122954824-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:328)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:291)
		at java.base/java.nio.file.Files.move(Files.java:1430)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:955)
		... 18 more
[2024-11-26 18:10:19,904] WARN [ReplicaManager broker=0] Stopping serving replicas in dir D:\GR1\kafka\tmp\kafka-logs with uuid None because the log directory has failed. (kafka.server.ReplicaManager)
[2024-11-26 18:10:19,914] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:19,915] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data_real_time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:19,925] WARN [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions data_real_time-0 and stopped moving logs for partitions  because they are in the failed log directory D:\GR1\kafka\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2024-11-26 18:10:19,925] WARN Stopping serving logs in dir D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:10:19,928] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:19,928] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(data-real-time-2, data-real-time-1, data-real-time-0) (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:19,930] ERROR Shutdown broker because all log dirs in D:\GR1\kafka\tmp\kafka-logs have failed (kafka.log.LogManager)
[2024-11-26 18:10:20,417] WARN Close of session 0x100003f51070000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:10:36,837] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:10:36,974] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:10:37,040] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:10:37,041] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:10:37,056] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:37,062] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,062] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,062] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,062] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,062] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,062] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,064] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,065] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,065] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,065] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,066] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:37,102] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:10:37,108] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:37,109] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:37,110] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:37,112] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:49724, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:37,117] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100003f51070001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:37,119] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:37,246] INFO Cluster ID = Bz5e5pWeQIGLaqXVm5dTjQ (kafka.server.KafkaServer)
[2024-11-26 18:10:37,289] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:10:37,318] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:37,319] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:37,319] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:37,321] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:37,350] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:37,376] INFO Recovering 4 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:10:37,406] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-0. (kafka.log.LogLoader)
[2024-11-26 18:10:37,407] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,408] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,408] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,422] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,423] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,423] INFO [LogLoader partition=data-real-time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,436] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-0, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 55ms (1/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:37,438] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-1. (kafka.log.LogLoader)
[2024-11-26 18:10:37,438] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,439] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,439] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,441] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,441] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,442] INFO [LogLoader partition=data-real-time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,444] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-1, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (2/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:37,446] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data-real-time-2. (kafka.log.LogLoader)
[2024-11-26 18:10:37,446] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,447] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,447] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,449] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,449] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,449] INFO [LogLoader partition=data-real-time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,452] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data-real-time-2, topicId=MxLc4xvbTFOzrZooGIfacg, topic=data-real-time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (3/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:37,456] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:10:37,456] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,456] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,456] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,458] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,459] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,459] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:10:37,461] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=7xgyyE_uSJuI326uXE4O0Q, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (4/4 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:10:37,465] INFO Loaded 4 logs in 114ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:10:37,467] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:10:37,467] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:10:37,520] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:10:37,532] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:10:37,552] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:10:37,576] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,842] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:10:37,859] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:10:37,863] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,879] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,879] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,879] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,879] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,880] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,893] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:10:37,893] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:10:37,938] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:10:37,951] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100003f51070000' does not match current session '0x100003f51070001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:10:37,955] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:10:37,956] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:10:37,957] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:10:37,959] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:10:37,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:10:37,965] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:10:37,965] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:10:37,966] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:10:37,966] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:10:37,966] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:37,967] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:10:37,967] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:37,967] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:10:37,967] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,968] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,968] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,969] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,969] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,969] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,970] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,970] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,970] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,971] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,971] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,971] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,971] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,972] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,972] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:10:37,976] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:10:37,976] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:10:37,976] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:10:37,977] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:10:37,977] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,977] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,977] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,979] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:10:37,979] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,979] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,979] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:10:37,981] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:10:37,982] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:10:37,983] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:10:37,991] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:10:37,991] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:10:38,032] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:10:38,035] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:10:38,035] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:10:38,035] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:10:38,037] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:38,146] INFO Session: 0x100003f51070001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:10:38,146] INFO EventThread shut down for session: 0x100003f51070001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:10:38,148] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:10:38,148] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,150] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,150] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,150] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,150] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,150] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,152] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:10:38,153] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:10:38,168] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:10:38,169] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:10:38,169] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:10:38,170] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:10:38,173] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:10:38,173] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:10:38,174] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:10:38,175] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:10:39,049] INFO Expiring session 0x100003f51070000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,769] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,773] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,773] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,773] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,773] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,774] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:11:48,774] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:11:48,775] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:11:48,775] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:11:48,776] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:11:48,777] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,777] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:11:48,777] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,778] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,778] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,778] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:11:48,778] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:11:48,782] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:11:48,791] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:11:48,794] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:11:48,794] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:11:48,794] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:11:48,799] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,799] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,799] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,799] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,799] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,799] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,801] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,801] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,801] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,802] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,806] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,807] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,808] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,809] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,809] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,809] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,809] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,809] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,810] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,812] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:11:48,813] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,813] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,814] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:11:48,815] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:11:48,815] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,816] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,816] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,816] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,817] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,817] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:11:48,819] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,820] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,820] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:11:48,820] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:11:48,820] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,831] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:11:48,832] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:11:48,833] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:11:48,874] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:11:48,887] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:11:48,888] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:11:48,888] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:11:48,888] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:11:48,895] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:11:48,895] INFO Snapshotting: 0x0 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:11:48,899] INFO Snapshot loaded in 11 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:11:48,901] INFO Snapshotting: 0x0 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:11:48,902] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:11:48,911] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:11:48,911] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:11:48,927] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:11:48,928] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:11:56,333] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:11:56,484] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:11:56,562] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:11:56,563] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:11:56,580] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:11:56,584] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,584] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,584] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,584] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,584] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,584] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,585] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,586] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,586] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,586] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,586] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,587] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,588] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,589] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,622] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:11:56,628] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:11:56,630] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:11:56,631] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:11:56,632] INFO Socket connection established, initiating session, client: /127.0.0.1:49783, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:11:56,641] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:11:56,656] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000040e0d80000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:11:56,659] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:11:56,870] INFO Cluster ID = OpBwJa5wRfmMvv7Tdpz3zA (kafka.server.KafkaServer)
[2024-11-26 18:11:56,875] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:11:56,877] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:11:56,881] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:11:56,988] INFO Session: 0x1000040e0d80000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:11:56,989] INFO EventThread shut down for session: 0x1000040e0d80000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:11:56,990] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:11:56,995] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:11:56,995] INFO shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:11:56,997] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:11:56,997] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:12:05,088] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:12:05,228] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:12:05,301] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:12:05,301] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:12:05,317] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:05,321] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,321] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,321] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,321] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,321] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,322] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,323] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,323] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,323] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,323] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,323] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,324] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,325] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,326] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,374] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:12:05,379] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:05,380] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:05,381] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:05,383] INFO Socket connection established, initiating session, client: /127.0.0.1:49805, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:05,387] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000040e0d80001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:05,389] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:05,561] INFO Cluster ID = OpBwJa5wRfmMvv7Tdpz3zA (kafka.server.KafkaServer)
[2024-11-26 18:12:05,569] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:12:05,572] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:12:05,576] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:05,689] INFO EventThread shut down for session: 0x1000040e0d80001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:05,689] INFO Session: 0x1000040e0d80001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:05,694] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:05,698] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:12:05,699] INFO shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:12:05,699] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:12:05,700] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:12:16,408] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:12:16,545] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:12:16,611] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:12:16,612] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:12:16,626] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:16,629] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,629] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,629] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,629] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,629] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,629] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,630] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,630] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,631] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,634] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,669] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:12:16,675] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:16,677] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:16,678] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:16,680] INFO Socket connection established, initiating session, client: /127.0.0.1:49814, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:16,686] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000040e0d80002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:16,688] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:16,826] INFO Cluster ID = OpBwJa5wRfmMvv7Tdpz3zA (kafka.server.KafkaServer)
[2024-11-26 18:12:16,831] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:12:16,832] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:12:16,836] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:16,946] INFO Session: 0x1000040e0d80002 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:12:16,946] INFO EventThread shut down for session: 0x1000040e0d80002 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:12:16,947] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:12:16,952] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:12:16,952] INFO shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:12:16,952] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:12:16,953] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:13:12,845] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:13:12,987] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:13:13,051] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:13:13,052] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:13:13,067] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:13:13,071] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,071] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,071] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,071] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,071] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,071] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,073] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,073] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,074] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,076] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,111] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:13:13,116] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:13:13,118] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:13:13,119] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:13:13,120] INFO Socket connection established, initiating session, client: /127.0.0.1:49886, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:13:13,125] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000040e0d80003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:13:13,127] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:13:13,251] INFO Cluster ID = OpBwJa5wRfmMvv7Tdpz3zA (kafka.server.KafkaServer)
[2024-11-26 18:13:13,255] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:13:13,257] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:13:13,261] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:13:13,370] INFO Session: 0x1000040e0d80003 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:13:13,370] INFO EventThread shut down for session: 0x1000040e0d80003 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:13:13,374] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:13:13,381] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:13:13,382] INFO shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:13:13,382] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:13:13,383] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:15:24,442] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,444] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,444] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,444] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,444] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,445] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:15:24,446] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:15:24,446] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:15:24,446] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:15:24,447] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:15:24,447] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,448] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,448] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,448] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,448] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:15:24,448] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:15:24,449] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:15:24,458] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:15:24,460] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:15:24,463] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:15:24,465] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:15:24,465] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:15:24,466] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:15:24,471] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,471] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,471] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,471] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,471] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,471] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,472] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,472] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,472] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,472] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,473] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,473] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,473] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,473] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,475] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,475] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,481] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,482] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,483] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:15:24,484] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,484] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,485] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:15:24,485] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:15:24,486] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,486] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,487] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,487] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,487] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,487] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:15:24,489] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,489] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,489] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:15:24,489] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:15:24,490] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,496] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:15:24,497] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:15:24,498] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:15:24,535] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:15:24,549] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:15:24,550] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:15:24,551] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:15:24,551] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:15:24,551] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:15:24,554] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:15:24,584] INFO 73 txns loaded in 14 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:15:24,585] INFO Snapshot loaded in 34 ms, highest zxid is 0x49, digest is 38073830924 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:15:24,586] INFO Snapshotting: 0x49 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.49 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:15:24,587] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:15:24,595] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:15:24,596] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:15:24,616] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:15:24,618] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:15:32,197] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:15:32,335] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:15:32,401] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:15:32,401] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:15:32,417] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:15:32,420] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,420] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,420] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,421] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,421] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,421] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,421] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,422] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,423] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,423] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,424] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,457] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:15:32,464] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:15:32,465] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:15:32,466] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:15:32,468] INFO Socket connection established, initiating session, client: /127.0.0.1:50201, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:15:32,473] INFO Creating new log file: log.4a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:15:32,479] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000442b5e0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:15:32,481] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:15:32,621] INFO Cluster ID = OpBwJa5wRfmMvv7Tdpz3zA (kafka.server.KafkaServer)
[2024-11-26 18:15:32,626] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:15:32,628] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:15:32,632] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:15:32,739] INFO Session: 0x10000442b5e0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:15:32,739] INFO EventThread shut down for session: 0x10000442b5e0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:15:32,741] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:15:32,746] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:15:32,746] INFO shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:15:32,747] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
java.lang.RuntimeException: Invalid cluster.id in: D:\GR1\kafka\tmp\kafka-logs\meta.properties. Expected OpBwJa5wRfmMvv7Tdpz3zA, but read Bz5e5pWeQIGLaqXVm5dTjQ
	at org.apache.kafka.metadata.properties.MetaPropertiesEnsemble.verify(MetaPropertiesEnsemble.java:503)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:258)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:15:32,747] INFO shutting down (kafka.server.KafkaServer)
[2024-11-26 18:17:34,913] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,916] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,916] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,916] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,916] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,917] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:17:34,917] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:17:34,918] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:17:34,918] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:17:34,919] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:17:34,919] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,920] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,920] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,920] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,920] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:17:34,920] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:17:34,921] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:17:34,927] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:17:34,933] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:17:34,935] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:17:34,935] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:17:34,935] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:17:34,940] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,940] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,940] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,940] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,941] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,946] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,947] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,947] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,947] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,947] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,947] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,948] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,949] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,949] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,949] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:17:34,950] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,951] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,951] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:17:34,952] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:17:34,952] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,952] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,953] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,953] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,953] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,953] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:17:34,955] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,955] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,956] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:17:34,956] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:17:34,956] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:34,966] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:17:34,967] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:17:34,968] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:17:35,007] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:17:35,018] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:17:35,019] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:17:35,019] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:17:35,019] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:17:35,026] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:17:35,026] INFO Snapshotting: 0x0 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:17:35,031] INFO Snapshot loaded in 11 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:17:35,032] INFO Snapshotting: 0x0 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:17:35,032] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:17:35,041] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:17:35,041] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:17:35,059] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:17:35,059] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:17:43,627] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:17:43,764] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:17:43,838] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:17:43,839] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:17:43,855] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:17:43,858] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,858] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,859] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,859] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,859] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,859] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,860] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,861] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,861] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,861] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,861] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,861] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,862] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,864] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:17:43,896] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:17:43,901] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:17:43,903] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:17:43,903] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:17:43,906] INFO Socket connection established, initiating session, client: /127.0.0.1:50535, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:17:43,913] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:17:43,922] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100004628eb0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:17:43,924] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:17:44,133] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:17:44,174] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:17:44,200] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:17:44,201] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:17:44,201] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:17:44,203] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:17:44,207] INFO [KafkaServer id=0] Rewriting D:/GR1/kafka/tmp/kafka-logs\meta.properties (kafka.server.KafkaServer)
[2024-11-26 18:17:44,276] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:17:44,282] INFO No logs found to be loaded in D:\GR1\kafka\tmp\kafka-logs (kafka.log.LogManager)
[2024-11-26 18:17:44,289] INFO Loaded 0 logs in 12ms (kafka.log.LogManager)
[2024-11-26 18:17:44,292] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:17:44,296] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:17:44,358] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:17:44,376] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:17:44,386] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)
[2024-11-26 18:17:44,403] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:17:44,699] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:17:44,720] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:17:44,727] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:17:44,748] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,749] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,749] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,750] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,751] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,769] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:17:44,769] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:17:44,798] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:17:44,816] INFO Stat of the created znode at /brokers/ids/0 is: 25,25,1732619864811,1732619864811,1,0,0,72057895372128256,214,0,25
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:17:44,817] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[2024-11-26 18:17:44,850] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,857] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,857] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:44,860] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2024-11-26 18:17:44,871] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:17:44,874] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)
[2024-11-26 18:17:44,878] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:17:44,905] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:17:44,905] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:17:44,909] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:17:44,909] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:17:44,957] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:17:45,005] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:17:45,017] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:17:45,020] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:17:45,022] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:17:45,022] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:17:45,023] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:17:45,023] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:17:45,029] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:17:45,030] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:17:45,030] INFO Kafka startTimeMs: 1732619865023 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:17:45,031] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:17:45,602] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:17:45,602] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:18:59,017] INFO Creating topic data_real_time with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 2 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2024-11-26 18:18:59,090] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data_real_time-1, data_real_time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:18:59,135] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:18:59,148] INFO Created log for partition data_real_time-0 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-0 with properties {} (kafka.log.LogManager)
[2024-11-26 18:18:59,149] INFO [Partition data_real_time-0 broker=0] No checkpointed highwatermark is found for partition data_real_time-0 (kafka.cluster.Partition)
[2024-11-26 18:18:59,150] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:18:59,165] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:18:59,167] INFO Created log for partition data_real_time-1 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-1 with properties {} (kafka.log.LogManager)
[2024-11-26 18:18:59,167] INFO [Partition data_real_time-1 broker=0] No checkpointed highwatermark is found for partition data_real_time-1 (kafka.cluster.Partition)
[2024-11-26 18:18:59,168] INFO [Partition data_real_time-1 broker=0] Log loaded for partition data_real_time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:18:59,176] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:18:59,177] INFO Created log for partition data_real_time-2 in D:\GR1\kafka\tmp\kafka-logs\data_real_time-2 with properties {} (kafka.log.LogManager)
[2024-11-26 18:18:59,177] INFO [Partition data_real_time-2 broker=0] No checkpointed highwatermark is found for partition data_real_time-2 (kafka.cluster.Partition)
[2024-11-26 18:18:59,179] INFO [Partition data_real_time-2 broker=0] Log loaded for partition data_real_time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:19:25,635] WARN Session 0x100004628eb0000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:19:27,235] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:27,238] WARN Session 0x100004628eb0000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1060)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:19:34,372] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,375] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,375] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,375] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,375] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,377] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:19:34,378] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:19:34,378] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:19:34,378] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:19:34,378] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:19:34,379] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,379] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,380] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,380] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,380] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:19:34,380] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:19:34,380] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:19:34,388] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:19:34,392] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:19:34,397] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:19:34,399] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:19:34,400] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:19:34,400] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:19:34,405] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,405] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,405] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,405] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,405] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,406] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,406] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,406] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,406] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,406] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,411] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,411] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,412] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,412] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,412] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,412] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,418] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,419] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,420] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:19:34,421] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,421] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,422] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:19:34,422] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:19:34,423] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,423] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,423] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,424] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,424] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,424] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:19:34,426] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,426] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,427] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:19:34,427] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:19:34,427] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,434] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:19:34,435] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:19:34,437] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:19:34,481] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:19:34,497] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:19:34,497] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:19:34,498] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:19:34,498] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:19:34,499] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:19:34,503] INFO The digest value is empty in snapshot (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:19:34,532] INFO 39 txns loaded in 12 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:19:34,532] INFO Snapshot loaded in 35 ms, highest zxid is 0x27, digest is 64466046721 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:19:34,533] INFO Snapshotting: 0x27 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:19:34,536] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:19:34,544] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:19:34,544] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:19:34,561] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:19:34,561] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:19:44,526] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:19:44,670] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:19:44,739] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:19:44,740] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:19:44,758] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:19:44,760] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,760] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,761] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,761] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,761] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,761] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,761] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,762] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,764] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:44,803] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:19:44,809] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:44,811] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:19:44,812] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:44,814] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:50773, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:44,819] INFO Creating new log file: log.28 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:19:44,826] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000047fbba0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:44,829] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:19:44,973] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:19:45,015] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:19:45,040] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,041] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,041] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,043] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,076] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:19:45,100] INFO Recovering 3 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:19:45,132] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:19:45,133] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,134] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,134] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,154] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,155] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,156] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,176] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 73ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:19:45,178] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-1. (kafka.log.LogLoader)
[2024-11-26 18:19:45,178] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,179] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,179] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,185] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,185] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,185] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,189] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:19:45,191] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-2. (kafka.log.LogLoader)
[2024-11-26 18:19:45,192] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,192] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,192] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,197] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,197] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,198] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:19:45,201] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:19:45,203] INFO Loaded 3 logs in 127ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:19:45,206] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:19:45,207] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:19:45,262] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:19:45,273] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:19:45,285] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:19:45,302] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,550] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:19:45,568] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:19:45,571] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,587] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,588] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,588] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,589] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,591] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,605] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:19:45,608] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:19:45,668] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:19:45,684] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100004628eb0000' does not match current session '0x1000047fbba0000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:19:45,690] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:19:45,692] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:19:45,693] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:19:45,696] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:19:45,703] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:19:45,706] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:19:45,707] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:19:45,707] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:19:45,707] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:19:45,707] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:19:45,708] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:19:45,709] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:19:45,709] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:19:45,709] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,710] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,710] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,710] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,710] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,710] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,711] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,711] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,711] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,714] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:19:45,718] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:19:45,719] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:19:45,719] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:19:45,719] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:19:45,720] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,721] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,721] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,722] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:19:45,722] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,722] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,722] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:19:45,723] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:19:45,723] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:19:45,724] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:19:45,725] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:19:45,725] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:19:45,775] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:19:45,779] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:19:45,780] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:19:45,780] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:19:45,780] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:19:45,893] INFO Session: 0x1000047fbba0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:19:45,893] INFO EventThread shut down for session: 0x1000047fbba0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:19:45,895] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:19:45,896] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,897] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,898] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,898] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,898] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:19:45,898] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:19:45,913] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:19:45,913] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:19:45,914] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:19:45,915] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:19:45,918] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:19:45,918] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:19:45,918] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:19:45,919] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:19:53,043] INFO Expiring session 0x100004628eb0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,316] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,318] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,318] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,318] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,318] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,319] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:20:03,320] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:20:03,320] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:20:03,320] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:20:03,321] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:20:03,321] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,322] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,322] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,322] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,322] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:20:03,323] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:20:03,323] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:20:03,331] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:20:03,339] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:20:03,341] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:20:03,342] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:20:03,342] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:20:03,342] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:20:03,346] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,346] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,347] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,348] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,350] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,350] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,350] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,351] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,351] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,351] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,353] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,353] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,353] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,354] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,354] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,354] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,355] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,355] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,356] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,356] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,356] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,357] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,357] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,357] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,358] INFO Server environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,358] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,358] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,358] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,359] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,359] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,359] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,359] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,360] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,360] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,360] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,361] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:20:03,362] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,362] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,363] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:20:03,363] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:20:03,365] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,366] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,366] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,367] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,367] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,367] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:20:03,369] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,369] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,370] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:20:03,370] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:20:03,370] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,383] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:20:03,384] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:20:03,385] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:20:03,421] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:20:03,435] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:20:03,436] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:20:03,436] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:20:03,437] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:20:03,437] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:20:03,444] INFO The digest in the snapshot has digest version of 2, with zxid as 0x27, and digest value as 64466046721 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:20:03,464] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:20:03,465] INFO 18 txns loaded in 5 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:20:03,465] INFO Snapshot loaded in 29 ms, highest zxid is 0x39, digest is 62450109956 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:20:03,466] INFO Snapshotting: 0x39 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:20:03,468] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:20:03,474] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:20:03,475] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:20:03,489] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:20:13,376] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:20:13,526] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:20:13,594] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:20:13,594] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:20:13,610] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:20:13,617] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,617] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,618] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,618] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,618] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,618] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,619] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,620] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,620] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,620] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,621] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,621] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,621] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,622] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,622] INFO Client environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,622] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,622] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,623] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,624] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:20:13,659] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:20:13,664] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:20:13,665] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:20:13,666] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:20:13,668] INFO Socket connection established, initiating session, client: /127.0.0.1:50827, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:20:13,673] INFO Creating new log file: log.3a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:20:13,681] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000486cbd0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:20:13,683] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:20:13,829] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:20:13,869] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:20:13,895] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:20:13,896] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:20:13,896] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:20:13,898] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:20:13,927] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:20:13,948] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:20:13,989] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:20:13,999] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 47ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:20:14,002] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:20:14,004] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 4ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:20:14,008] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:20:14,010] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:20:14,012] INFO Loaded 3 logs in 84ms (kafka.log.LogManager)
[2024-11-26 18:20:14,014] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:20:14,014] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:20:14,069] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:20:14,078] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:20:14,096] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:20:14,119] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:20:14,396] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:20:14,411] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:20:14,417] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:20:14,433] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,434] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,434] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,436] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,437] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,451] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:20:14,452] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:20:14,500] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:20:14,524] INFO Stat of the created znode at /brokers/ids/0 is: 73,73,1732620014515,1732620014515,1,0,0,72057905099898880,214,0,73
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:20:14,526] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 73 (kafka.zk.KafkaZkClient)
[2024-11-26 18:20:14,564] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,572] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,573] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,583] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:20:14,589] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:20:14,625] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:20:14,630] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:20:14,634] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:20:14,682] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:20:14,731] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:20:14,758] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:20:14,760] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:20:14,763] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:20:14,763] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:20:14,764] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:20:14,765] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:20:14,768] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:20:14,769] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:20:14,770] INFO Kafka startTimeMs: 1732620014765 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:20:14,773] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:20:15,274] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data_real_time-1, data_real_time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:20:15,274] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:20:15,290] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:20:15,304] INFO [Partition data_real_time-1 broker=0] Log loaded for partition data_real_time-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:20:15,308] INFO [Partition data_real_time-2 broker=0] Log loaded for partition data_real_time-2 with initial high watermark 0 (kafka.cluster.Partition)
[2024-11-26 18:20:15,321] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:20:38,316] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:39,298] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:40,309] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:41,318] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:42,333] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:43,307] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:44,361] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:45,367] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:46,380] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:47,388] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:48,308] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:49,407] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:50,414] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:51,417] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:52,421] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:53,309] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:54,446] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:55,460] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:56,466] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:57,480] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:58,317] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:20:59,498] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:00,508] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:01,523] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:02,535] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:03,329] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:04,551] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:05,565] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:06,573] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:07,583] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:08,341] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:09,598] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:10,608] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:11,619] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:12,626] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:13,354] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:14,642] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:15,662] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:16,662] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:17,669] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:18,366] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:19,690] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:20,698] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:21,710] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:22,767] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:23,369] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:24,778] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:25,788] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:26,800] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:27,809] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:28,384] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:28,815] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:29,816] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:30,829] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:31,844] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:32,852] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:33,386] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:34,876] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:35,881] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:36,891] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:37,893] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:38,388] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:38,900] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:39,907] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:40,919] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:41,926] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:42,933] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:43,946] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:44,954] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:45,961] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:46,969] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:47,975] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:48,980] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:49,991] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:50,999] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:52,009] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:53,024] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:54,033] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:55,043] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:56,051] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:57,062] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:58,072] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:21:59,081] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:00,082] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:01,094] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:02,103] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:03,114] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:04,121] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:05,128] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:06,138] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:07,149] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:08,157] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:09,164] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:10,173] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:11,178] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:12,193] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:13,202] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:14,214] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:15,224] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:16,238] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:17,247] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:18,260] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:19,266] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:20,275] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:21,281] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:22,288] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:23,302] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:24,309] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:25,324] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:26,331] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:27,345] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:28,353] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:29,363] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:30,377] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:31,380] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:32,392] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:33,400] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:34,405] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:35,405] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:36,417] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:37,431] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:38,440] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:39,440] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:40,446] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:41,454] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:42,466] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:43,475] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:44,485] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:45,495] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:46,506] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:47,508] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:48,499] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:49,526] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:50,535] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:51,545] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:52,559] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:53,509] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:54,576] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:55,583] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:56,596] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:57,603] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:58,523] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:22:59,627] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:00,636] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:01,645] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:02,653] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:03,534] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:04,673] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:05,683] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:06,694] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:07,703] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:08,537] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:09,716] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:10,722] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:11,727] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:12,737] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:13,544] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:14,757] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:15,764] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:16,771] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:17,781] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:18,558] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:19,797] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:20,804] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:21,815] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:22,829] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:23,561] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:24,851] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:25,865] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:26,874] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:27,877] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:28,564] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:29,903] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:30,917] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:31,930] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:32,938] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:33,576] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:34,960] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:35,971] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:36,978] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:37,992] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:39,001] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:40,016] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:41,025] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:42,034] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:43,045] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:43,588] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:44,054] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:45,065] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:46,076] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:47,078] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:48,085] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:48,601] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:49,086] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:50,091] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:51,099] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:52,109] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:53,120] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:53,602] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:54,130] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:55,140] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:56,149] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:57,161] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:58,172] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:23:59,187] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:00,197] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:01,211] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:02,227] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:03,242] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:04,253] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:05,266] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:06,275] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:07,288] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:08,299] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:09,312] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:10,323] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:11,326] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:12,339] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:13,350] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:14,365] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:15,375] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:16,379] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:17,387] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:18,399] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:19,413] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:20,420] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:21,426] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:22,439] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:23,446] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:24,462] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:25,466] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:26,473] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:27,483] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:28,493] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:29,498] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:30,512] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:31,522] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:32,529] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:33,538] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:34,549] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:35,565] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:36,573] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:37,583] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:38,586] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:39,594] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:40,604] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:41,612] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:42,625] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:43,635] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:44,649] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:45,657] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:46,667] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:47,672] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:48,678] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:49,688] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:50,696] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:51,703] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:52,714] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:53,691] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:54,723] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:55,735] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:56,744] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:57,753] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:58,701] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:24:59,769] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:00,775] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:01,784] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:02,796] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:03,710] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:04,816] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:05,820] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:06,826] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:07,839] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:08,725] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:09,856] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:10,865] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:11,875] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:12,884] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:13,736] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:14,900] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:15,905] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:16,913] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:17,925] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:18,751] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:19,948] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:20,961] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:21,973] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:22,981] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:23,755] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:24,990] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:25,998] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:27,007] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:25:27,392] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:25:27,396] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2024-11-26 18:25:27,407] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 4ms (kafka.server.KafkaServer)
[2024-11-26 18:25:27,410] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:25:27,410] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:25:27,410] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:25:27,411] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:25:27,422] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:25:27,424] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2024-11-26 18:25:27,427] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2024-11-26 18:25:27,428] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,429] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,429] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,432] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2024-11-26 18:25:27,433] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,433] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,433] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,435] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:25:27,436] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2024-11-26 18:25:27,436] INFO [TxnMarkerSenderThread-0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:25:27,437] INFO [TxnMarkerSenderThread-0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:25:27,437] INFO [TxnMarkerSenderThread-0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:25:27,438] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:25:27,439] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:25:27,440] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,440] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,440] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,443] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,444] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,444] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,445] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:25:27,445] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:25:27,446] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:25:27,446] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:25:27,446] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:25:27,448] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:25:27,449] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:25:27,450] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:25:27,450] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:25:27,450] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,450] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,451] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,451] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,452] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,452] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,452] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,453] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,453] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,454] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,454] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,454] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,454] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,455] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,455] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:25:27,459] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:25:27,459] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:25:27,460] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:25:27,460] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:25:27,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,461] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,463] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:25:27,463] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,465] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,465] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:25:27,466] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:25:27,467] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:25:27,468] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:25:27,468] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:25:27,468] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:25:27,479] INFO [ProducerStateManager partition=data_real_time-1] Wrote producer snapshot at offset 32 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:25:27,485] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 47 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:25:27,490] INFO [ProducerStateManager partition=data_real_time-2] Wrote producer snapshot at offset 46 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:25:27,518] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:25:27,522] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:25:27,522] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:25:27,522] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:25:27,524] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:25:27,812] INFO Session: 0x10000486cbd0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:25:27,812] INFO EventThread shut down for session: 0x10000486cbd0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:25:27,813] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:25:27,814] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,815] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,815] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,815] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,816] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,816] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,816] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,817] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,817] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,817] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,818] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,818] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:25:27,819] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:25:27,830] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:25:27,832] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:25:27,833] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:25:27,833] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:25:27,836] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:25:27,837] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:25:27,837] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:30:09,017] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,020] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,020] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,020] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,020] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,021] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:09,021] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:09,022] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:30:09,022] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:09,023] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:30:09,023] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,023] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,024] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,024] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,024] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:09,024] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:30:09,025] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:09,034] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:30:09,042] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:30:09,045] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:30:09,045] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:09,045] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:30:09,046] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:09,052] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,052] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,052] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,053] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,053] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,053] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,053] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,053] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,054] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,054] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,056] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,058] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,058] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,058] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,058] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,058] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,059] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,059] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,060] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,060] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,060] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,060] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,061] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,061] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,061] INFO Server environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,061] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,061] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,062] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,062] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,062] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,062] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,063] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,063] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,063] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,063] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,065] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:30:09,066] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,067] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,068] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:30:09,068] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:30:09,069] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,069] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,069] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,070] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,070] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,070] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:09,071] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,072] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,073] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:30:09,074] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:30:09,074] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,084] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:30:09,085] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:30:09,086] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:30:09,128] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:30:09,143] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:30:09,143] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:30:09,143] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:09,143] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:09,144] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:30:09,148] INFO The digest in the snapshot has digest version of 2, with zxid as 0x39, and digest value as 62450109956 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:30:09,173] INFO 30 txns loaded in 7 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:09,174] INFO Snapshot loaded in 31 ms, highest zxid is 0x57, digest is 69736801922 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:09,175] INFO Snapshotting: 0x57 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.57 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:09,178] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:09,186] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:30:09,186] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:30:09,200] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:30:09,200] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:30:19,136] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:30:19,289] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:30:19,404] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:30:19,405] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:30:19,422] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:30:19,426] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,426] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,427] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,429] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,429] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,429] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,433] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,433] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,434] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,434] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,434] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,434] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,437] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,438] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,438] INFO Client environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,438] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,439] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,439] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,441] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:19,480] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:30:19,485] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:30:19,488] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:30:19,489] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:30:19,491] INFO Socket connection established, initiating session, client: /127.0.0.1:52775, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:30:19,498] INFO Creating new log file: log.58 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:30:19,504] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000051aacb0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:30:19,507] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:30:19,679] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:30:19,721] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:30:19,749] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:19,749] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:19,749] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:19,751] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:19,783] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:30:19,807] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:30:19,866] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,867] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,868] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:30:19,882] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 15ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,891] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 80ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:30:19,907] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,907] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,907] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:30:19,908] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,910] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 17ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:30:19,922] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,922] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,922] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:30:19,924] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:30:19,927] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 16ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:30:19,930] INFO Loaded 3 logs in 146ms (kafka.log.LogManager)
[2024-11-26 18:30:19,933] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:30:19,933] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:30:19,983] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:30:19,993] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:30:20,010] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:30:20,030] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,294] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:30:20,311] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:30:20,315] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,332] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,333] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,333] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,334] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,335] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,351] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:30:20,355] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:30:20,407] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:30:20,425] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x10000486cbd0000' does not match current session '0x1000051aacb0000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:30:20,431] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:30:20,433] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:30:20,435] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:30:20,438] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:30:20,446] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:30:20,448] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:30:20,448] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:30:20,448] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:30:20,449] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:30:20,449] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:30:20,450] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:30:20,451] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:30:20,451] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:30:20,451] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,452] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,453] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,454] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,455] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,455] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,455] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,456] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,456] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,456] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,456] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,456] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,457] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,457] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,458] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:30:20,463] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:30:20,464] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:30:20,464] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:30:20,465] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:30:20,465] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,466] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,466] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,467] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:30:20,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:30:20,468] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:30:20,470] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:30:20,480] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:30:20,480] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:30:20,480] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:30:20,525] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:30:20,528] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:30:20,528] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:30:20,528] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:30:20,529] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:30:20,648] INFO Session: 0x1000051aacb0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:30:20,648] INFO EventThread shut down for session: 0x1000051aacb0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:30:20,649] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:30:20,649] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,650] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,650] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,653] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,653] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,653] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,655] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,656] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,656] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,656] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,657] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,657] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:30:20,658] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:30:20,682] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:30:20,684] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:30:20,684] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:30:20,687] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:30:20,690] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:30:20,690] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:30:20,690] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:30:20,691] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:30:53,683] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,686] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,686] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,686] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,686] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,687] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:53,687] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:53,687] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:30:53,687] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:53,688] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:30:53,688] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,689] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,689] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,689] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,689] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:30:53,689] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:30:53,689] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:53,698] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:30:53,707] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:30:53,709] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:30:53,710] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:30:53,712] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:53,712] INFO Removing file: Nov 26, 2024, 6:17:35PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.0 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:30:53,713] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:30:53,717] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,717] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,717] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,717] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,717] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,717] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,718] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,719] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,719] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,719] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,723] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,724] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,724] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,724] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,724] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,724] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,731] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,731] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,731] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,731] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,732] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,733] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,733] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,733] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,733] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,733] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:30:53,734] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,734] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,735] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:30:53,736] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,737] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:30:53,739] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,739] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,740] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:30:53,740] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:30:53,740] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,748] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:30:53,748] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:30:53,749] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:30:53,788] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:30:53,804] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:30:53,805] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:30:53,805] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:53,806] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:53,806] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.57 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:30:53,813] INFO The digest in the snapshot has digest version of 2, with zxid as 0x57, and digest value as 69736801922 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:30:53,839] INFO 17 txns loaded in 3 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:53,840] INFO Snapshot loaded in 33 ms, highest zxid is 0x68, digest is 69736801922 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:30:53,840] INFO Snapshotting: 0x68 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.68 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:30:53,842] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:30:53,850] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:30:53,850] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:30:53,866] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:30:53,867] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:31:01,481] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:31:01,625] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:31:01,698] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:31:01,699] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:31:01,714] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:01,718] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,718] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,719] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,719] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,719] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,719] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,720] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,720] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,720] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,721] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,721] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,721] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,721] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,721] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,722] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,722] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,722] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,722] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,724] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:01,764] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:31:01,771] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:01,773] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:01,774] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:01,776] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:52877, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:01,782] INFO Creating new log file: log.69 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:31:01,789] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100005259440000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:01,791] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:01,951] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:31:02,000] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:31:02,030] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,030] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,030] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,032] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,077] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:02,099] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:31:02,185] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,187] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,187] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:02,195] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,211] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 107ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:02,218] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,219] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,219] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:02,219] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,221] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 9ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:02,229] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,229] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,229] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:02,230] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:02,232] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 11ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:02,233] INFO Loaded 3 logs in 156ms (kafka.log.LogManager)
[2024-11-26 18:31:02,237] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:31:02,239] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:31:02,317] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:02,339] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:02,357] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:31:02,390] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,669] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:31:02,686] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:31:02,690] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,705] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,707] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,707] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,708] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,709] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,724] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:02,724] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:02,772] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:31:02,788] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x10000486cbd0000' does not match current session '0x100005259440000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:31:02,790] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:02,791] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:31:02,792] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:31:02,795] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:02,799] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:31:02,801] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:31:02,801] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:02,801] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:02,801] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:02,804] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:31:02,804] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:31:02,805] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:31:02,805] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:31:02,805] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,806] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,806] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,807] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,807] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,807] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,807] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,808] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,809] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,809] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:02,814] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:02,814] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:02,814] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:02,815] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:31:02,815] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,815] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,815] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,816] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:31:02,816] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,816] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,816] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:02,817] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:31:02,817] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:31:02,819] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:02,823] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:02,823] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:02,860] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:31:02,863] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:02,863] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:02,863] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:02,864] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:02,971] INFO Session: 0x100005259440000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:02,971] INFO EventThread shut down for session: 0x100005259440000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:02,972] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:02,973] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,975] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,975] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,975] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,976] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,976] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,976] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,976] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,976] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,977] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,977] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,977] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:02,986] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:31:02,999] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:31:03,000] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:31:03,000] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:31:03,005] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:31:03,008] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:31:03,009] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:31:03,009] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:03,010] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:31:06,092] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:31:06,237] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:31:06,306] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:31:06,308] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:31:06,326] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:06,329] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,329] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,329] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,329] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,331] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,331] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,331] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,332] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,333] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,334] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:06,372] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:31:06,378] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:06,379] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:06,381] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:06,383] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:52891, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:06,389] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100005259440001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:06,391] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:06,526] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:31:06,570] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:31:06,598] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:06,598] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:06,599] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:06,601] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:06,630] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:06,650] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:31:06,700] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,700] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,700] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:06,706] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,716] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 60ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:06,722] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,722] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,722] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:06,722] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,725] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 8ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:06,731] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,731] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,731] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:06,731] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:06,733] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 9ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:06,735] INFO Loaded 3 logs in 105ms (kafka.log.LogManager)
[2024-11-26 18:31:06,738] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:31:06,739] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:31:06,798] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:06,810] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:06,827] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:31:06,854] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,140] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:31:07,158] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:31:07,163] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,179] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,179] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,180] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,181] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,181] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,195] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:07,196] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:07,253] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:31:07,267] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x10000486cbd0000' does not match current session '0x100005259440001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:31:07,271] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:07,272] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:31:07,274] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:31:07,275] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:07,281] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:31:07,282] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:31:07,283] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:07,283] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:07,283] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:07,283] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:31:07,284] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:31:07,284] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:31:07,285] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:31:07,285] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,286] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,286] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,288] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,288] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,288] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,288] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,289] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,289] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,290] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,290] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,290] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,292] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,292] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,292] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:07,300] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:07,300] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:07,300] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:07,301] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:31:07,301] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,301] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,301] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,301] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:31:07,302] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,303] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,303] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:07,304] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:31:07,304] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:31:07,305] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:07,306] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:07,306] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:07,356] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:31:07,359] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:07,359] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:07,359] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:07,359] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:07,474] INFO Session: 0x100005259440001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:07,474] INFO EventThread shut down for session: 0x100005259440001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:07,476] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:07,476] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,480] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,480] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,481] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,482] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,482] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:07,483] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:31:07,500] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:31:07,500] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:31:07,500] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:31:07,503] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:31:07,506] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:31:07,507] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:31:07,507] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:31:07,508] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:31:13,042] INFO Expiring session 0x10000486cbd0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:31:22,735] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:31:22,878] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:31:22,951] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:31:22,952] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:31:22,967] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:22,971] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,971] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,972] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,972] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,972] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,972] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,973] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,973] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,974] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,975] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,975] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,975] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:22,977] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:31:23,011] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:31:23,017] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:23,019] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:23,019] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:23,021] INFO Socket connection established, initiating session, client: /127.0.0.1:52948, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:23,026] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005259440002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:31:23,029] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:31:23,180] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:31:23,233] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:31:23,265] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:23,265] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:23,265] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:23,267] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:31:23,308] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:23,329] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:31:23,397] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,398] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,399] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:23,403] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,417] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 83ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:23,426] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,426] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,426] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:23,427] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,428] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 11ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:23,435] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,436] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,436] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:31:23,436] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:31:23,439] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 10ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:31:23,443] INFO Loaded 3 logs in 134ms (kafka.log.LogManager)
[2024-11-26 18:31:23,445] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:31:23,445] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:31:23,512] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:31:23,522] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:31:23,541] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:31:23,575] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:23,855] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:31:23,874] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:31:23,878] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:23,894] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:23,895] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:23,896] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:23,897] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:23,897] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:23,914] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:31:23,915] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:31:23,959] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:31:23,974] INFO Stat of the created znode at /brokers/ids/0 is: 155,155,1732620683968,1732620683968,1,0,0,72057947722874882,214,0,155
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:31:23,974] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 155 (kafka.zk.KafkaZkClient)
[2024-11-26 18:31:24,014] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:24,020] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:24,021] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:24,034] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:31:24,037] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:31:24,055] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:31:24,059] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:31:24,059] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:31:24,111] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:31:24,141] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:31:24,163] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:31:24,165] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:31:24,167] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:31:24,167] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:31:24,167] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:31:24,168] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:31:24,171] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:31:24,171] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:31:24,171] INFO Kafka startTimeMs: 1732620684168 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:31:24,172] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:31:24,631] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:24,631] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:31:24,654] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data_real_time-1, data_real_time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:31:24,684] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 47 (kafka.cluster.Partition)
[2024-11-26 18:31:24,695] INFO [Partition data_real_time-1 broker=0] Log loaded for partition data_real_time-1 with initial high watermark 32 (kafka.cluster.Partition)
[2024-11-26 18:31:24,696] INFO [Partition data_real_time-2 broker=0] Log loaded for partition data_real_time-2 with initial high watermark 46 (kafka.cluster.Partition)
[2024-11-26 18:32:59,107] WARN Session 0x100005259440002 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:33:00,562] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:00,563] WARN Session 0x100005259440002 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1060)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:33:02,352] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:02,353] WARN Session 0x100005259440002 for server localhost/[0:0:0:0:0:0:0:1]:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: getsockopt
	at java.base/sun.nio.ch.Net.pollConnect(Native Method)
	at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:682)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:1060)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)
[2024-11-26 18:33:09,011] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,014] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,014] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,014] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,014] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,015] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:09,015] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:09,016] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:33:09,016] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:09,017] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:33:09,019] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,019] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,019] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,020] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,020] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:09,020] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:09,020] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:33:09,034] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:33:09,042] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:33:09,044] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:09,044] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:09,044] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:09,047] INFO Removing file: Nov 26, 2024, 6:18:59PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.1 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:09,048] INFO Removing file: Nov 26, 2024, 6:19:34PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.27 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:09,049] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:09,051] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,051] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,051] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,051] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,051] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,053] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,053] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,053] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,054] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,054] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,056] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,056] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,056] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,056] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,056] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,057] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,063] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,063] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,063] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,064] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,064] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,064] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,064] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,065] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,066] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,066] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,066] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,066] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,067] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:33:09,068] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,068] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,070] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:09,071] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:09,072] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,072] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,073] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,073] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,073] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,073] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:09,075] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,076] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,077] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:09,077] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:09,077] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,086] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:09,088] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:09,091] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:09,144] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:09,156] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:33:09,156] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:33:09,156] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:09,156] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:09,157] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.68 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:33:09,163] INFO The digest in the snapshot has digest version of 2, with zxid as 0x68, and digest value as 69736801922 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:33:09,196] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:33:09,199] INFO 53 txns loaded in 7 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:09,199] INFO Snapshot loaded in 41 ms, highest zxid is 0x9d, digest is 67987603056 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:09,199] INFO Snapshotting: 0x9d to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.9d (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:09,201] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:09,209] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:33:09,209] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:33:09,224] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:33:17,199] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:33:17,348] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:33:17,430] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:33:17,430] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:33:17,447] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:17,451] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,451] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,451] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,451] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,451] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,452] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,452] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,453] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,453] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,453] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,453] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,453] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,454] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,456] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:17,494] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:33:17,500] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:17,501] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:17,502] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:17,504] INFO Socket connection established, initiating session, client: /127.0.0.1:53167, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:17,509] INFO Creating new log file: log.9e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:33:17,516] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10000546a040000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:17,519] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:17,684] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:33:17,733] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:33:17,758] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:17,758] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:17,759] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:17,760] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:17,796] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:17,816] INFO Recovering 3 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:33:17,851] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:33:17,853] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,853] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,853] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:33:17,854] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,880] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 47 with 0 producer ids in 4 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,886] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,886] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,886] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,889] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,899] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 78ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:17,902] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-1. (kafka.log.LogLoader)
[2024-11-26 18:33:17,903] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,903] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,903] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:33:17,904] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,909] INFO [ProducerStateManager partition=data_real_time-1] Wrote producer snapshot at offset 32 with 0 producer ids in 2 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,912] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,912] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,912] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,915] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,916] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 16ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:17,919] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-2. (kafka.log.LogLoader)
[2024-11-26 18:33:17,920] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,920] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,920] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:33:17,921] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,928] INFO [ProducerStateManager partition=data_real_time-2] Wrote producer snapshot at offset 46 with 0 producer ids in 1 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,931] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,931] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,931] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:17,932] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:17,934] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 18ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:17,938] INFO Loaded 3 logs in 141ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:33:17,940] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:33:17,941] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:33:17,998] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:18,013] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:18,038] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:33:18,063] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,309] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:33:18,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:33:18,332] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,348] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,349] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,349] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,349] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,350] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,360] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:18,360] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:18,415] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:33:18,433] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100005259440002' does not match current session '0x10000546a040000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:33:18,438] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:18,440] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:33:18,441] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:33:18,443] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:18,448] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:33:18,450] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:33:18,451] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:18,451] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:18,451] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:18,452] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:33:18,452] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:33:18,452] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:33:18,453] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:33:18,453] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,454] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,454] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,455] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,455] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,455] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,457] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,458] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,458] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:18,464] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:18,464] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:18,464] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:18,465] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:33:18,465] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,465] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,465] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,466] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:33:18,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,467] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:18,468] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:33:18,471] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:33:18,472] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:18,476] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:18,476] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:18,519] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:33:18,522] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:18,522] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:18,522] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:18,523] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:18,640] INFO Session: 0x10000546a040000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:18,640] INFO EventThread shut down for session: 0x10000546a040000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:18,641] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:18,641] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,644] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,644] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,644] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,645] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,645] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,645] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,645] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,645] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,646] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,646] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,646] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:18,648] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:33:18,671] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:33:18,674] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:33:18,674] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:33:18,676] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:33:18,681] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:33:18,682] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:33:18,682] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:18,683] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:33:26,073] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:33:26,214] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:33:26,292] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:33:26,292] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:33:26,310] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:26,316] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,318] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,318] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,318] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,318] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,318] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,319] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,319] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,320] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,320] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,320] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,320] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,320] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,321] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,321] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,321] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,321] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,321] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,324] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:26,370] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:33:26,375] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:26,376] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:26,377] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:26,379] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:53186, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:26,384] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000546a040001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:26,386] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:26,525] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:33:26,571] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:33:26,599] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:26,599] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:26,599] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:26,601] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:26,638] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:26,657] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:33:26,733] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,734] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,734] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:26,739] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,753] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 90ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:26,760] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,761] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,761] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:26,762] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,764] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 10ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:26,771] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,771] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,771] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:33:26,772] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:33:26,774] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 10ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:33:26,777] INFO Loaded 3 logs in 138ms (kafka.log.LogManager)
[2024-11-26 18:33:26,779] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:33:26,779] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:33:26,839] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:26,863] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:26,887] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:33:26,922] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,198] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:33:27,215] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:33:27,219] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,235] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,235] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,237] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,239] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,240] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,259] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:27,260] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:27,314] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:33:27,326] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x100005259440002' does not match current session '0x10000546a040001' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:33:27,329] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:27,330] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:33:27,331] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:33:27,333] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:27,338] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:33:27,340] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:33:27,340] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:27,341] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:27,341] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:33:27,341] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:33:27,342] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:33:27,342] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:33:27,342] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:33:27,342] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,343] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,343] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,343] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,344] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,344] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,344] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,344] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,344] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,345] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,345] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,345] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,346] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,346] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,346] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:33:27,351] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:27,351] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:27,351] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:33:27,352] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:33:27,352] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,352] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,352] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,353] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:33:27,353] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,353] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,353] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:33:27,354] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:33:27,354] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:33:27,355] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:27,356] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:27,356] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:33:27,401] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:33:27,403] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:27,404] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:27,404] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:33:27,405] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:27,516] INFO Session: 0x10000546a040001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:33:27,516] INFO EventThread shut down for session: 0x10000546a040001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:33:27,518] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:33:27,518] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,521] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,522] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,522] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,522] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,522] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,523] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:33:27,531] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:33:27,545] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:33:27,547] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:33:27,547] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:33:27,550] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:33:27,552] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:33:27,553] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:33:27,553] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:33:27,554] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:33:29,041] INFO Expiring session 0x100005259440002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,182] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,185] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,185] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,185] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,185] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,186] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:41,186] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:41,187] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:33:41,187] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:41,188] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:33:41,188] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,189] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,189] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,189] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,189] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:41,189] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:33:41,189] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:41,198] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:33:41,203] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:33:41,204] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:41,204] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:41,205] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:41,209] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,210] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,211] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,211] INFO Removing file: Nov 26, 2024, 6:19:53PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.28 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:41,212] INFO Removing file: Nov 26, 2024, 6:20:03PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.39 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:41,212] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:41,215] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,215] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,215] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,215] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,215] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,216] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,221] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,221] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,223] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,224] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:33:41,225] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,225] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,226] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:41,227] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:41,227] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,227] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,227] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,228] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,228] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,228] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:41,230] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,230] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,230] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:41,230] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:41,231] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,236] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:41,236] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:41,239] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:41,280] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:41,292] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:33:41,292] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:33:41,292] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:41,293] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:41,293] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.9d (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:33:41,299] INFO The digest in the snapshot has digest version of 2, with zxid as 0x9d, and digest value as 67987603056 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:33:41,326] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:33:41,327] INFO 35 txns loaded in 5 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:41,327] INFO Snapshot loaded in 34 ms, highest zxid is 0xc0, digest is 64708026070 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:33:41,327] INFO Snapshotting: 0xc0 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.c0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:41,330] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:41,336] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:33:41,336] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:33:41,353] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:33:51,086] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,089] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,089] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,089] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,089] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,090] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:51,091] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:51,091] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:33:51,091] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:51,092] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:33:51,092] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,093] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,093] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,093] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,093] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:33:51,093] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:33:51,094] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:51,103] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:33:51,108] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:33:51,110] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:51,110] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:33:51,111] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:33:51,113] INFO Removing file: Nov 26, 2024, 6:24:08PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.3a (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:51,114] INFO Removing file: Nov 26, 2024, 6:30:09PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.57 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:33:51,114] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:33:51,116] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,116] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,116] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,116] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,116] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,118] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,118] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,119] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,119] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,119] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,120] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,121] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,121] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,121] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,121] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,121] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,128] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,128] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,128] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,128] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,129] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,130] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,131] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:33:51,132] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,132] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,133] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:51,133] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,134] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:33:51,135] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,137] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,139] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:51,139] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:33:51,140] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:33:51,149] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:51,150] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:33:51,151] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:51,187] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:33:51,188] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:565)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:344)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:301)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:89)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:81)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:662)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:160)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:113)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:68)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:141)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:91)
[2024-11-26 18:33:51,193] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:33:51,194] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2024-11-26 18:34:00,539] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:34:00,686] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:34:00,760] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:34:00,761] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:34:00,777] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:34:00,782] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,783] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,783] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,783] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,783] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,783] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,784] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,786] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,786] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,787] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:34:00,822] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:34:00,828] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:34:00,830] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:34:00,832] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:34:00,834] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:53260, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:34:00,839] INFO Creating new log file: log.c1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:34:00,847] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000054e7830000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:34:00,849] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:34:00,992] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:34:01,040] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:34:01,069] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:34:01,070] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:34:01,070] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:34:01,071] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:34:01,108] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:34:01,150] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:34:01,200] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 47 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,201] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,201] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=47, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:34:01,206] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 47 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,217] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=47) with 1 segments, local-log-start-offset 0 and log-end-offset 47 in 62ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:34:01,223] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 32 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,223] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,224] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=32, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:34:01,224] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 32 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,226] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=32) with 1 segments, local-log-start-offset 0 and log-end-offset 32 in 9ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:34:01,233] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 46 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,233] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,233] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=46, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:34:01,234] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 46 (kafka.log.UnifiedLog$)
[2024-11-26 18:34:01,237] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=46) with 1 segments, local-log-start-offset 0 and log-end-offset 46 in 11ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:34:01,240] INFO Loaded 3 logs in 131ms (kafka.log.LogManager)
[2024-11-26 18:34:01,241] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:34:01,242] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:34:01,295] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:34:01,306] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:34:01,323] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:34:01,347] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:34:01,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:34:01,629] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:34:01,633] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:34:01,649] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,649] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,649] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,650] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,650] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,664] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:34:01,664] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:34:01,715] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:34:01,734] INFO Stat of the created znode at /brokers/ids/0 is: 208,208,1732620841725,1732620841725,1,0,0,72057958699302912,214,0,208
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:34:01,735] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 208 (kafka.zk.KafkaZkClient)
[2024-11-26 18:34:01,775] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,782] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,783] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,796] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:34:01,802] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:34:01,834] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:34:01,845] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:34:01,855] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:34:01,914] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:34:01,938] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:34:01,963] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:34:01,965] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:34:01,967] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:34:01,968] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:34:01,968] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:34:01,968] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:34:01,972] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:34:01,972] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:34:01,972] INFO Kafka startTimeMs: 1732620841968 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:34:01,973] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:34:02,457] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:34:02,463] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data_real_time-1, data_real_time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:34:02,476] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 47 (kafka.cluster.Partition)
[2024-11-26 18:34:02,480] INFO [Partition data_real_time-1 broker=0] Log loaded for partition data_real_time-1 with initial high watermark 32 (kafka.cluster.Partition)
[2024-11-26 18:34:02,481] INFO [Partition data_real_time-2 broker=0] Log loaded for partition data_real_time-2 with initial high watermark 46 (kafka.cluster.Partition)
[2024-11-26 18:34:02,518] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:40:10,657] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:40:10,812] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:40:10,894] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:40:10,894] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:40:10,914] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:10,918] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,918] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,918] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,918] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,918] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,919] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,919] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,920] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,921] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,921] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,921] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,922] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,923] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:10,961] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:40:10,967] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:10,969] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:10,970] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:10,972] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:53893, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:10,978] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x1000054e7830001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:10,979] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:11,118] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:40:11,161] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:40:11,192] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,192] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,193] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,194] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,214] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\GR1\kafka\tmp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:270)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArrayBuffer.flatMap(ArrayBuffer.scala:42)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:265)
	at kafka.log.LogManager.<init>(LogManager.scala:128)
	at kafka.log.LogManager$.apply(LogManager.scala:1599)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:325)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:40:11,216] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:40:11,220] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:11,333] INFO Session: 0x1000054e7830001 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:11,333] INFO EventThread shut down for session: 0x1000054e7830001 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:11,335] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:11,335] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,338] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,338] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,338] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,338] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,338] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,339] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:11,340] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:40:11,340] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:40:11,342] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:40:11,346] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:40:11,349] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:40:11,349] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\GR1\kafka\tmp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:270)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArrayBuffer.flatMap(ArrayBuffer.scala:42)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:265)
	at kafka.log.LogManager.<init>(LogManager.scala:128)
	at kafka.log.LogManager$.apply(LogManager.scala:1599)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:325)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:40:11,350] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:40:14,286] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:40:14,430] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:40:14,505] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:40:14,505] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:40:14,522] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:14,526] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,527] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,527] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,527] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,527] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,528] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,528] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,529] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,529] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,529] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,530] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,531] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,532] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,569] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:40:14,575] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:14,578] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:14,579] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:14,582] INFO Socket connection established, initiating session, client: /127.0.0.1:53895, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:14,588] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000054e7830002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:14,590] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:14,744] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:40:14,801] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:40:14,830] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,830] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,831] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,833] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,849] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\GR1\kafka\tmp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:270)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArrayBuffer.flatMap(ArrayBuffer.scala:42)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:265)
	at kafka.log.LogManager.<init>(LogManager.scala:128)
	at kafka.log.LogManager$.apply(LogManager.scala:1599)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:325)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:40:14,851] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:40:14,854] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:14,971] INFO Session: 0x1000054e7830002 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:40:14,971] INFO EventThread shut down for session: 0x1000054e7830002 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:40:14,972] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:40:14,973] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,974] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,974] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,975] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,975] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,975] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,975] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,976] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,976] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,976] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,976] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,976] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:40:14,978] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:40:14,978] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:40:14,980] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:40:14,984] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:40:14,985] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:40:14,985] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\GR1\kafka\tmp\kafka-logs. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:270)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:118)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:105)
	at scala.collection.mutable.ArrayBuffer.flatMap(ArrayBuffer.scala:42)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:265)
	at kafka.log.LogManager.<init>(LogManager.scala:128)
	at kafka.log.LogManager$.apply(LogManager.scala:1599)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:325)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:40:14,986] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:40:35,689] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,691] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,691] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,692] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,692] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,693] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:35,693] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:35,693] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:40:35,693] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:35,694] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:40:35,695] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,695] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,695] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,695] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,696] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:35,696] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:40:35,697] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:40:35,708] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:40:35,711] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:35,722] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:40:35,726] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:40:35,726] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:40:35,726] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:40:35,733] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,733] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,734] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,734] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,734] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,735] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,735] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,735] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,735] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,736] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,738] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,738] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,738] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,739] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,739] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,739] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,760] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,760] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,761] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,761] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,761] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,761] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,762] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,762] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,762] INFO Server environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,763] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,763] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,763] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,763] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,764] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,764] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,764] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,764] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,764] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,765] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,766] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:40:35,767] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,767] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,768] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:40:35,769] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:40:35,769] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,770] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,770] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,771] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,771] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,771] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:35,773] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,773] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,774] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:40:35,775] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:40:35,776] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:35,782] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:40:35,783] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:40:35,784] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:40:35,815] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:40:35,816] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:565)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:344)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:301)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:89)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:81)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:662)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:160)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:113)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:68)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:141)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:91)
[2024-11-26 18:40:35,819] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:40:35,820] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2024-11-26 18:40:39,006] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,008] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,009] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,009] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,009] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,010] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:39,011] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:39,011] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:40:39,011] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:39,012] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:40:39,013] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,014] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,014] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,015] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,015] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:40:39,016] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:40:39,017] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:40:39,026] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:40:39,029] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:40:39,035] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:40:39,036] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:40:39,037] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:40:39,037] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:40:39,041] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,041] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,042] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,042] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,042] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,042] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,044] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,044] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,044] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,044] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,045] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,047] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,047] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,049] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,049] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,049] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,057] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,057] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,057] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,058] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,058] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,058] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,058] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,059] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,059] INFO Server environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,059] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,059] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,059] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,060] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,060] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,060] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,060] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,061] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,061] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,061] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,064] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:40:39,065] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,065] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,066] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:40:39,067] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:40:39,067] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,068] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,068] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,068] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,068] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,069] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:40:39,070] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,071] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,071] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:40:39,071] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:40:39,071] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:40:39,078] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:40:39,079] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:40:39,081] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:40:39,117] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:40:39,118] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:565)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.netBind(ServerSocketChannelImpl.java:344)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:301)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:89)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:81)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:662)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:160)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:113)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:68)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:141)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:91)
[2024-11-26 18:40:39,121] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:40:39,123] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2024-11-26 18:42:01,314] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:02,298] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:03,310] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:04,318] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:05,331] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:06,311] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:07,356] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:08,366] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:09,379] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:10,386] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:11,322] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:12,414] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:13,415] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:14,424] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:15,432] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:16,334] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:17,456] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:18,470] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:19,479] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:20,489] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:21,346] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:22,506] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:23,515] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:24,529] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:25,545] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:26,352] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:27,566] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:28,574] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:29,583] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:30,595] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:31,357] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:32,615] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:33,627] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:34,635] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:35,640] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:36,370] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:37,655] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:38,664] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:39,678] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:40,691] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:41,378] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:42,716] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:43,723] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:44,733] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:45,744] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:46,383] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:47,768] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:48,771] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:49,786] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:50,788] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:51,395] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:52,814] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:53,827] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:54,838] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:55,848] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:56,408] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:57,869] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:58,883] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:42:59,884] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:00,894] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:01,900] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:02,911] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:03,921] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:04,934] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:05,947] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:06,426] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:06,956] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:07,959] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:08,970] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:09,981] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:10,991] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:11,993] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:13,003] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:14,016] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:15,026] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:16,038] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:17,052] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:18,062] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:19,072] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:20,081] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:21,093] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:22,105] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:23,117] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:24,123] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:25,130] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:26,142] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:27,151] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:28,158] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:29,165] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:30,179] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:31,188] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:32,191] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:33,200] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:34,214] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:35,227] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:36,232] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:37,237] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:38,250] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:39,258] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:40,266] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:41,276] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:42,282] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:43,293] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:44,303] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:45,312] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:46,323] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:47,332] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:48,337] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:49,346] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:50,355] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:51,365] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:52,377] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:53,386] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:54,400] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:55,408] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:56,409] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:57,420] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:58,429] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:43:59,443] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:00,448] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:01,452] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:02,465] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:03,476] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:04,489] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:05,501] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:06,512] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:07,521] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:08,531] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:09,545] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:10,555] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:11,564] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:12,574] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:13,584] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:14,589] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:15,593] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:16,570] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:17,611] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:18,619] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:19,631] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:20,637] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:21,582] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:22,655] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:23,664] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:24,675] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:25,689] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:26,587] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:27,704] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:28,716] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:29,724] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:30,733] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:31,603] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:32,751] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:33,756] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:34,763] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:35,772] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:36,614] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:37,795] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:38,802] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:39,813] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:40,823] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:41,615] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:42,844] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:43,851] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:44,861] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:45,870] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:46,617] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:47,893] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:48,898] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:49,907] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:50,913] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:51,628] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:52,930] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:53,933] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:54,933] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:55,956] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:56,639] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:57,972] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:58,980] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:44:59,993] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:01,002] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:01,640] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:03,021] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:04,032] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:05,042] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:06,051] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:06,655] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:08,066] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:09,075] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:10,088] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:11,094] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:11,667] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:13,114] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:14,121] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:15,143] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:16,146] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:16,676] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:17,158] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:18,166] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:19,171] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:20,175] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:21,186] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:21,687] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:23,203] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:24,211] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:25,218] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:26,224] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:26,688] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:28,237] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:29,240] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:30,248] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:31,253] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:32,259] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:33,271] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:34,279] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:35,282] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:36,291] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:37,301] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:38,311] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:39,317] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:40,318] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:41,329] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:42,335] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:43,341] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:44,355] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:45,364] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:46,376] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:47,383] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:48,391] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:49,404] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:50,416] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:51,425] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:52,435] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:53,443] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:54,452] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:55,465] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:56,468] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:57,474] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:58,487] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:45:59,498] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:00,501] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:01,508] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:02,516] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:03,517] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:04,524] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:05,533] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:06,545] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:07,551] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:08,559] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:09,566] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:10,575] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:11,585] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:12,588] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:13,602] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:14,613] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:15,626] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:16,635] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:17,638] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:18,638] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:19,642] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:20,649] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:21,657] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:22,660] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:23,668] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:24,679] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:25,683] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:26,691] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:27,697] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:28,705] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:29,708] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:30,713] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:31,721] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:32,727] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:33,731] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:34,736] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:35,739] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:36,745] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:37,752] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:38,767] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:39,777] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:40,778] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:41,786] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:42,790] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:43,806] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:44,820] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:45,822] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:46,823] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:47,827] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:48,827] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:49,829] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:50,843] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:51,828] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:52,859] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:53,872] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:54,877] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:55,891] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:56,834] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:57,906] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:58,908] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:46:59,917] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:00,921] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:01,840] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:02,944] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:03,953] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:04,956] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:05,962] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:06,845] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:07,979] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:08,989] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:58,466] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:47:59,468] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:00,474] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:01,486] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:02,498] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:03,469] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:04,503] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:05,514] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:06,520] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:07,530] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:08,483] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:09,555] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:10,568] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:11,582] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:12,588] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:13,491] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:14,613] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:15,622] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:16,636] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:17,645] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:18,501] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:19,663] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:20,673] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:21,680] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:22,687] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:23,509] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:24,695] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:25,700] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:26,706] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:27,715] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:28,517] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:29,720] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:30,730] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:31,739] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:32,750] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:33,530] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:34,764] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:35,774] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:36,785] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:37,795] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:38,541] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:39,814] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:40,825] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:41,834] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:42,840] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:43,541] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:44,856] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:45,859] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:46,864] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:47,869] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:48,555] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:49,880] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:50,888] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:51,900] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:52,911] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:53,561] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:54,930] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:55,944] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:56,954] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:57,961] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:58,566] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:48:59,982] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:00,993] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:02,004] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:03,011] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:03,571] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:05,031] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:06,055] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:07,066] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:08,076] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:08,587] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:09,082] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:10,088] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:11,097] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:12,106] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:13,112] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:13,594] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:14,123] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:15,138] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:16,143] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:17,144] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:18,153] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:19,159] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:49:19,929] WARN Close of session 0x1000054e7830000 (org.apache.zookeeper.server.NIOServerCnxn)
java.net.SocketException: Connection reset
	at java.base/sun.nio.ch.SocketChannelImpl.throwConnectionReset(SocketChannelImpl.java:403)
	at java.base/sun.nio.ch.SocketChannelImpl.implRead(SocketChannelImpl.java:435)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:493)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:334)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:508)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:153)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1570)
[2024-11-26 18:50:20,333] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,335] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,335] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,335] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,335] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,336] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:20,337] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:20,337] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:50:20,337] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:20,338] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:50:20,338] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,339] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,341] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,341] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,340] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:20,341] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:20,342] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:50:20,353] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:50:20,358] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:20,363] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:50:20,365] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:50:20,366] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:50:20,367] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:20,371] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,371] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,371] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,372] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,373] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,376] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,376] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,377] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,377] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,377] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,377] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,387] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,387] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,387] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,388] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,388] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,388] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,389] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,389] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,390] INFO Server environment:user.dir=D:\GR1\Code (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,390] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,390] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,391] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,392] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,392] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,393] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,393] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,393] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,393] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,394] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,395] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:50:20,396] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,396] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,397] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:50:20,397] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:50:20,399] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,400] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,400] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,401] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,401] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,401] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:20,402] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,403] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,404] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:50:20,404] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:50:20,404] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,411] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:50:20,413] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:50:20,416] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:50:20,475] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:50:20,493] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:50:20,504] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:50:20,505] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:20,507] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:20,508] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.c0 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:50:20,518] INFO The digest in the snapshot has digest version of 2, with zxid as 0xc0, and digest value as 64708026070 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:50:20,575] INFO 72 txns loaded in 14 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:20,575] INFO Snapshot loaded in 68 ms, highest zxid is 0x108, digest is 69669091458 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:20,577] INFO Snapshotting: 0x108 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.108 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:20,583] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:20,594] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:50:20,594] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:50:20,644] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:50:20,670] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:50:30,383] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:50:30,541] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:50:30,614] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:50:30,615] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:50:30,632] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:30,637] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,637] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,637] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,637] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,637] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,637] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,641] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,642] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,642] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,643] INFO Client environment:user.dir=D:\GR1\Code (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,644] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,644] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,644] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,651] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:30,700] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:50:30,705] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:30,707] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:30,708] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:30,710] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:55376, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:30,717] INFO Creating new log file: log.109 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:50:30,726] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x100006426d90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:30,732] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:30,886] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:50:30,935] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:50:30,989] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:30,990] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:30,990] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:30,992] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:31,027] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:31,085] INFO Recovering 3 logs from D:\GR1\kafka\tmp\kafka-logs since no clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:50:31,135] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-0. (kafka.log.LogLoader)
[2024-11-26 18:50:31,135] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-1. (kafka.log.LogLoader)
[2024-11-26 18:50:31,135] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Recovering unflushed segment 0. 0/1 recovered for data_real_time-2. (kafka.log.LogLoader)
[2024-11-26 18:50:31,138] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,138] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,139] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,138] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,139] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,139] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,139] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000000046.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:50:31,140] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,140] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000000032.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:50:31,140] INFO Deleted producer state snapshot D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000000047.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-11-26 18:50:31,141] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,140] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,332] INFO [ProducerStateManager partition=data_real_time-0] Wrote producer snapshot at offset 5990 with 0 producer ids in 25 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,332] INFO [ProducerStateManager partition=data_real_time-2] Wrote producer snapshot at offset 6655 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,339] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5990 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,340] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,350] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=5990, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000005990.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,350] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 6655 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,353] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,353] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=6655, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000006655.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,366] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 13ms for snapshot load and 0ms for segment recovery from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,369] INFO [ProducerStateManager partition=data_real_time-1] Wrote producer snapshot at offset 5182 with 0 producer ids in 9 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,385] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 35ms for snapshot load and 0ms for segment recovery from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,402] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6655) with 1 segments, local-log-start-offset 0 and log-end-offset 6655 in 312ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:31,415] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5990) with 1 segments, local-log-start-offset 0 and log-end-offset 5990 in 327ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:31,427] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5182 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,431] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,432] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=5182, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000005182.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:31,434] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:31,436] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5182) with 1 segments, local-log-start-offset 0 and log-end-offset 5182 in 347ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:31,448] INFO Loaded 3 logs in 418ms (unclean log dirs = ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs)) (kafka.log.LogManager)
[2024-11-26 18:50:31,451] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:50:31,453] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:50:31,530] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:31,544] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:31,559] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:50:31,577] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:31,835] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:50:31,854] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:50:31,861] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:31,882] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:31,882] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:31,883] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:31,884] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:31,884] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:31,900] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:31,901] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:31,973] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:50:31,992] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x1000054e7830000' does not match current session '0x100006426d90000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:50:31,999] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:32,003] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:50:32,010] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:50:32,025] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:32,035] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:50:32,040] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:50:32,041] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:32,041] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:32,041] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:32,042] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:50:32,043] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:50:32,048] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:50:32,049] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:50:32,049] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,050] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,050] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,051] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,051] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,051] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,075] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,076] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,076] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,080] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,081] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,082] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,083] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,084] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,084] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:32,096] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:32,097] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:32,097] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:32,098] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:50:32,098] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,099] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,099] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,100] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:50:32,101] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,107] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,107] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:32,108] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:50:32,109] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:50:32,114] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:32,116] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:32,116] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:32,190] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:50:32,193] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:32,193] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:32,193] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:32,194] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:32,302] INFO Session: 0x100006426d90000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:32,302] INFO EventThread shut down for session: 0x100006426d90000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:32,303] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:32,304] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,306] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,306] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,306] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,306] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,306] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,307] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,307] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,307] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,308] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,308] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,308] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:32,309] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:50:32,334] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:50:32,335] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:50:32,337] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:50:32,339] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:50:32,342] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:50:32,343] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:50:32,343] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:32,348] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:50:47,123] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,126] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,127] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,127] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,127] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,128] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:47,128] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:47,128] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:50:47,128] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:47,129] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:50:47,129] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,130] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,130] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,130] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,130] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:50:47,130] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:50:47,130] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:47,136] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:50:47,143] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:50:47,146] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:50:47,146] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:50:47,146] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:47,146] INFO Removing file: Nov 26, 2024, 6:30:20PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.58 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:50:47,147] INFO Removing file: Nov 26, 2024, 6:30:53PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.68 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:50:47,147] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:50:47,153] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,153] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,153] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,153] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,154] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,156] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,156] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,156] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,157] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,157] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,157] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,164] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:user.dir=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,165] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,166] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,166] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,166] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,166] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,166] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,167] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:50:47,168] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,168] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,170] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:50:47,170] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:50:47,171] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,171] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,172] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,172] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,172] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,172] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:50:47,174] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,174] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,174] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:50:47,174] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:50:47,175] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,181] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:50:47,182] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:50:47,183] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:50:47,225] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:50:47,240] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:50:47,240] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:50:47,240] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:47,241] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:47,241] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.108 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:50:47,247] INFO The digest in the snapshot has digest version of 2, with zxid as 0x108, and digest value as 69669091458 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:50:47,269] INFO 17 txns loaded in 3 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:47,270] INFO Snapshot loaded in 29 ms, highest zxid is 0x119, digest is 69669091458 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:50:47,271] INFO Snapshotting: 0x119 to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.119 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:50:47,273] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:50:47,281] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:50:47,281] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:50:47,296] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:50:47,297] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:50:57,434] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:50:57,585] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:50:57,661] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:50:57,662] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:50:57,678] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:57,682] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,682] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,682] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,682] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,682] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,684] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,685] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,685] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,685] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,685] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,685] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:user.dir=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,686] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,688] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:57,723] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:50:57,729] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:57,731] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:57,732] INFO Opening socket connection to server localhost/[0:0:0:0:0:0:0:1]:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:57,734] INFO Socket connection established, initiating session, client: /[0:0:0:0:0:0:0:1]:54963, server: localhost/[0:0:0:0:0:0:0:1]:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:57,739] INFO Creating new log file: log.11a (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:50:57,745] INFO Session establishment complete on server localhost/[0:0:0:0:0:0:0:1]:2181, session id = 0x10000648f1a0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:57,749] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:57,908] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:50:57,954] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:50:57,981] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:57,982] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:57,982] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:57,983] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,016] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:58,046] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:50:58,107] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 6655 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,107] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5182 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,110] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,110] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=5182, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000005182.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:58,107] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5990 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,111] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,109] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,113] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=6655, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000006655.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:58,113] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=5990, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000005990.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:50:58,119] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,119] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,119] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:50:58,138] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5182) with 1 segments, local-log-start-offset 0 and log-end-offset 5182 in 87ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:58,143] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6655) with 1 segments, local-log-start-offset 0 and log-end-offset 6655 in 81ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:58,142] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5990) with 1 segments, local-log-start-offset 0 and log-end-offset 5990 in 92ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:50:58,149] INFO Loaded 3 logs in 133ms (kafka.log.LogManager)
[2024-11-26 18:50:58,153] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:50:58,154] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:50:58,238] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:58,254] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:58,278] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:50:58,295] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,537] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:50:58,553] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:50:58,557] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,575] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,575] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,576] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,576] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,577] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,586] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:58,586] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:58,652] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:50:58,668] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x1000054e7830000' does not match current session '0x10000648f1a0000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:50:58,672] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:58,674] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:50:58,674] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:50:58,676] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:58,691] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:50:58,694] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:50:58,694] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:58,695] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:58,695] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:50:58,695] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:50:58,696] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:50:58,697] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:50:58,698] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:50:58,698] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,699] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,699] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,700] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,700] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,700] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,700] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,701] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,701] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,701] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,701] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,701] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,702] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,702] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,702] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:50:58,708] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:58,708] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:58,708] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:50:58,709] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:50:58,709] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,709] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,709] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,709] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:50:58,710] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,710] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,710] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:50:58,711] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:50:58,711] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:50:58,712] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:58,714] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:58,715] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:50:58,760] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:50:58,763] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:58,765] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:58,765] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:50:58,765] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:58,871] INFO Session: 0x10000648f1a0000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:50:58,871] INFO EventThread shut down for session: 0x10000648f1a0000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:50:58,873] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:50:58,873] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,874] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,874] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,875] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,875] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,875] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,875] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,877] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,877] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,877] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,877] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,877] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:50:58,878] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:50:58,892] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:50:58,892] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:50:58,892] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:50:58,893] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:50:58,897] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:50:58,897] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:50:58,897] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:50:58,899] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:51:45,087] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,089] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,089] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,089] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,089] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,090] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:51:45,090] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:51:45,091] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:51:45,091] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:51:45,092] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:51:45,092] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,092] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,092] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,092] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,094] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:51:45,094] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:51:45,094] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:51:45,100] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:51:45,110] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:51:45,111] INFO Removing file: Nov 26, 2024, 6:31:24PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.69 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:51:45,112] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:51:45,113] INFO Removing file: Nov 26, 2024, 6:33:09PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.9d (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:51:45,114] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:51:45,115] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:51:45,115] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:51:45,121] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,121] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,122] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,123] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,123] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,125] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,125] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,125] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,125] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,126] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,128] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,128] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,128] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,129] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,129] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,129] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,136] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,136] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,137] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,137] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,137] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,137] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,138] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,138] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,138] INFO Server environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,138] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,139] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,139] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,139] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,140] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,140] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,140] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,142] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,142] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,144] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,145] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:51:45,146] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,146] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,147] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:51:45,147] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:51:45,148] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,148] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,149] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,149] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,149] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,149] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:51:45,151] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,151] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,152] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:51:45,152] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:51:45,152] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,158] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:51:45,160] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:51:45,162] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:51:45,201] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:51:45,219] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:51:45,220] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:51:45,220] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:51:45,221] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:51:45,222] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.119 (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:51:45,228] INFO The digest in the snapshot has digest version of 2, with zxid as 0x119, and digest value as 69669091458 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:51:45,247] INFO 17 txns loaded in 2 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:51:45,248] INFO Snapshot loaded in 28 ms, highest zxid is 0x12a, digest is 69669091458 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:51:45,250] INFO Snapshotting: 0x12a to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.12a (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:51:45,252] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:51:45,259] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:51:45,259] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:51:45,275] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:51:45,276] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:51:55,210] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:51:55,358] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:51:55,432] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:51:55,433] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:51:55,449] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:51:55,455] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,455] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,455] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,456] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,456] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,456] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,457] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,457] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,457] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,458] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,458] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,458] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,458] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,459] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,459] INFO Client environment:user.dir=C:\Windows\System32 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,459] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,459] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,459] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,461] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:55,495] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:51:55,500] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:51:55,501] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:51:55,502] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:51:55,504] INFO Socket connection established, initiating session, client: /127.0.0.1:55071, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:51:55,509] INFO Creating new log file: log.12b (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:51:55,516] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100006571960000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:51:55,519] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:51:55,667] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:51:55,709] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:51:55,740] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:55,741] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:55,741] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:55,742] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:55,773] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:51:55,796] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:51:55,856] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5990 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,857] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 6655 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,856] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5182 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,861] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,866] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=6655, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000006655.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:51:55,858] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,874] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=5990, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000005990.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:51:55,868] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,878] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 2ms for snapshot load and 2ms for segment recovery from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,875] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,878] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=5182, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000005182.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:51:55,884] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:51:55,903] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6655) with 1 segments, local-log-start-offset 0 and log-end-offset 6655 in 103ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:51:55,905] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5182) with 1 segments, local-log-start-offset 0 and log-end-offset 5182 in 106ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:51:55,907] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5990) with 1 segments, local-log-start-offset 0 and log-end-offset 5990 in 95ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:51:55,913] INFO Loaded 3 logs in 138ms (kafka.log.LogManager)
[2024-11-26 18:51:55,917] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:51:55,919] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:51:55,997] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:51:56,022] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:51:56,043] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:51:56,064] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,302] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:51:56,323] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:51:56,327] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,346] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,347] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,347] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,348] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,349] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,359] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:51:56,364] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:51:56,438] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:51:56,456] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '0x1000054e7830000' does not match current session '0x100006571960000' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2024-11-26 18:51:56,461] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:51:56,463] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:51:56,464] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:51:56,466] ERROR Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null (kafka.network.DataPlaneAcceptor)
java.lang.NullPointerException: Cannot invoke "java.nio.channels.ServerSocketChannel.close()" because the return value of "kafka.network.Acceptor.serverChannel()" is null
	at kafka.network.Acceptor.$anonfun$closeAll$2(SocketServer.scala:711)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.network.Acceptor.closeAll(SocketServer.scala:711)
	at kafka.network.Acceptor.close(SocketServer.scala:678)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4(SocketServer.scala:287)
	at kafka.network.SocketServer.$anonfun$stopProcessingRequests$4$adapted(SocketServer.scala:287)
	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:619)
	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:617)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:935)
	at kafka.network.SocketServer.stopProcessingRequests(SocketServer.scala:287)
	at kafka.server.KafkaServer.$anonfun$shutdown$4(KafkaServer.scala:997)
	at kafka.utils.CoreUtils$.swallow(CoreUtils.scala:68)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:997)
	at kafka.server.KafkaBroker.shutdown(KafkaBroker.scala:98)
	at kafka.server.KafkaBroker.shutdown$(KafkaBroker.scala:98)
	at kafka.server.KafkaServer.shutdown(KafkaServer.scala:112)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:679)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:51:56,474] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2024-11-26 18:51:56,482] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2024-11-26 18:51:56,483] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:51:56,484] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:51:56,484] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:51:56,489] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:51:56,490] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:51:56,492] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:51:56,493] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2024-11-26 18:51:56,493] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,497] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,497] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,506] INFO [ExpirationReaper-0-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,508] INFO [ExpirationReaper-0-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,508] INFO [ExpirationReaper-0-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,510] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,514] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,514] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,515] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,516] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,517] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,521] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,523] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,523] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:51:56,530] INFO [AddPartitionsToTxnSenderThread-0]: Shutting down (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:51:56,530] INFO [AddPartitionsToTxnSenderThread-0]: Stopped (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:51:56,530] INFO [AddPartitionsToTxnSenderThread-0]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:51:56,531] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2024-11-26 18:51:56,532] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,532] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,532] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,534] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:51:56,534] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,534] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,534] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:51:56,536] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)
[2024-11-26 18:51:56,538] INFO Shutting down. (kafka.log.LogManager)
[2024-11-26 18:51:56,541] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:51:56,542] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:51:56,542] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:51:56,586] INFO Shutdown complete. (kafka.log.LogManager)
[2024-11-26 18:51:56,589] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:51:56,589] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:51:56,589] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:51:56,592] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:51:56,712] INFO Session: 0x100006571960000 closed (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:51:56,712] INFO EventThread shut down for session: 0x100006571960000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:51:56,712] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:51:56,714] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,715] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,715] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,716] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,717] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,717] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,718] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,719] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,719] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,720] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,721] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,721] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:51:56,722] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2024-11-26 18:51:56,737] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2024-11-26 18:51:56,738] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:51:56,738] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2024-11-26 18:51:56,740] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2024-11-26 18:51:56,746] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:51:56,747] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2024-11-26 18:51:56,747] ERROR Exiting Kafka due to fatal exception during startup. (kafka.Kafka$)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:2239)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:2177)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:2144)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:111)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:407)
	at kafka.Kafka$.main(Kafka.scala:112)
	at kafka.Kafka.main(Kafka.scala)
[2024-11-26 18:51:56,748] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2024-11-26 18:52:05,041] INFO Expiring session 0x1000054e7830000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,328] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,331] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,331] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,331] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,331] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,332] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:52:39,332] INFO autopurge.purgeInterval set to 24 (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:52:39,333] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2024-11-26 18:52:39,333] INFO Purge task started. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:52:39,334] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2024-11-26 18:52:39,334] INFO Reading configuration from: D:\GR1\kafka\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,335] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,336] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,336] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:52:39,336] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,336] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2024-11-26 18:52:39,337] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2024-11-26 18:52:39,346] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2024-11-26 18:52:39,353] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@7ce3cb8e (org.apache.zookeeper.server.ServerMetrics)
[2024-11-26 18:52:39,356] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:52:39,356] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)
[2024-11-26 18:52:39,356] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:52:39,357] INFO Removing file: Nov 26, 2024, 6:33:29PM	D:\GR1\kafka\tmp\zookeeper\version-2\log.9e (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:52:39,359] INFO Removing file: Nov 26, 2024, 6:33:41PM	D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.c0 (org.apache.zookeeper.server.PurgeTxnLog)
[2024-11-26 18:52:39,364] INFO Purge task completed. (org.apache.zookeeper.server.DatadirCleanupManager)
[2024-11-26 18:52:39,365] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,365] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,365] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,365] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,365] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,366] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,366] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,366] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,369] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,369] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,372] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,372] INFO Server environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,373] INFO Server environment:java.version=22.0.2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,375] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,375] INFO Server environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,375] INFO Server environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,390] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,390] INFO Server environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,390] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,390] INFO Server environment:os.name=Windows 11 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:user.name=PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:user.home=C:\Users\PC (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:user.dir=D:\GR1\Code (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:os.memory.free=487MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,392] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,393] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,397] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,397] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,411] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,412] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,414] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,415] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2024-11-26 18:52:39,417] INFO minSessionTimeout set to 4000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,417] INFO maxSessionTimeout set to 40000 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,426] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:52:39,433] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2024-11-26 18:52:39,439] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,440] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,440] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,440] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,441] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,441] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2024-11-26 18:52:39,447] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,447] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,448] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:52:39,448] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)
[2024-11-26 18:52:39,449] INFO Created server with tickTime 2000 ms minSessionTimeout 4000 ms maxSessionTimeout 40000 ms clientPortListenBacklog -1 datadir D:\GR1\kafka\tmp\zookeeper\version-2 snapdir D:\GR1\kafka\tmp\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,463] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:52:39,465] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2024-11-26 18:52:39,472] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:52:39,552] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2024-11-26 18:52:39,571] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:52:39,572] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2024-11-26 18:52:39,572] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:52:39,572] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:52:39,572] INFO Reading snapshot D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.12a (org.apache.zookeeper.server.persistence.FileSnap)
[2024-11-26 18:52:39,584] INFO The digest in the snapshot has digest version of 2, with zxid as 0x12a, and digest value as 69669091458 (org.apache.zookeeper.server.DataTree)
[2024-11-26 18:52:39,617] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2024-11-26 18:52:39,617] INFO 18 txns loaded in 7 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:52:39,617] INFO Snapshot loaded in 44 ms, highest zxid is 0x13c, digest is 62875961577 (org.apache.zookeeper.server.ZKDatabase)
[2024-11-26 18:52:39,622] INFO Snapshotting: 0x13c to D:\GR1\kafka\tmp\zookeeper\version-2\snapshot.13c (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2024-11-26 18:52:39,623] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2024-11-26 18:52:39,632] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)
[2024-11-26 18:52:39,632] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2024-11-26 18:52:39,658] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2024-11-26 18:52:49,323] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-11-26 18:52:49,486] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-11-26 18:52:49,575] INFO starting (kafka.server.KafkaServer)
[2024-11-26 18:52:49,576] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2024-11-26 18:52:49,591] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:52:49,596] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,596] INFO Client environment:host.name=LAPTOP-RVLAKEFN (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,596] INFO Client environment:java.version=22.0.2 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,596] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,597] INFO Client environment:java.home=C:\Program Files\Java\jdk-22 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,597] INFO Client environment:java.class.path=D:\GR1\kafka\libs\activation-1.1.1.jar;D:\GR1\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\GR1\kafka\libs\argparse4j-0.7.0.jar;D:\GR1\kafka\libs\audience-annotations-0.12.0.jar;D:\GR1\kafka\libs\caffeine-2.9.3.jar;D:\GR1\kafka\libs\commons-beanutils-1.9.4.jar;D:\GR1\kafka\libs\commons-cli-1.4.jar;D:\GR1\kafka\libs\commons-collections-3.2.2.jar;D:\GR1\kafka\libs\commons-digester-2.1.jar;D:\GR1\kafka\libs\commons-io-2.14.0.jar;D:\GR1\kafka\libs\commons-lang3-3.12.0.jar;D:\GR1\kafka\libs\commons-logging-1.2.jar;D:\GR1\kafka\libs\commons-validator-1.7.jar;D:\GR1\kafka\libs\connect-api-3.9.0.jar;D:\GR1\kafka\libs\connect-basic-auth-extension-3.9.0.jar;D:\GR1\kafka\libs\connect-file-3.9.0.jar;D:\GR1\kafka\libs\connect-json-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-3.9.0.jar;D:\GR1\kafka\libs\connect-mirror-client-3.9.0.jar;D:\GR1\kafka\libs\connect-runtime-3.9.0.jar;D:\GR1\kafka\libs\connect-transforms-3.9.0.jar;D:\GR1\kafka\libs\error_prone_annotations-2.10.0.jar;D:\GR1\kafka\libs\hk2-api-2.6.1.jar;D:\GR1\kafka\libs\hk2-locator-2.6.1.jar;D:\GR1\kafka\libs\hk2-utils-2.6.1.jar;D:\GR1\kafka\libs\jackson-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-core-2.16.2.jar;D:\GR1\kafka\libs\jackson-databind-2.16.2.jar;D:\GR1\kafka\libs\jackson-dataformat-csv-2.16.2.jar;D:\GR1\kafka\libs\jackson-datatype-jdk8-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-base-2.16.2.jar;D:\GR1\kafka\libs\jackson-jaxrs-json-provider-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-afterburner-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-jaxb-annotations-2.16.2.jar;D:\GR1\kafka\libs\jackson-module-scala_2.13-2.16.2.jar;D:\GR1\kafka\libs\jakarta.activation-api-1.2.2.jar;D:\GR1\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\GR1\kafka\libs\jakarta.inject-2.6.1.jar;D:\GR1\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\GR1\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\GR1\kafka\libs\jakarta.xml.bind-api-2.3.3.jar;D:\GR1\kafka\libs\javassist-3.29.2-GA.jar;D:\GR1\kafka\libs\javax.activation-api-1.2.0.jar;D:\GR1\kafka\libs\javax.annotation-api-1.3.2.jar;D:\GR1\kafka\libs\javax.servlet-api-3.1.0.jar;D:\GR1\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\GR1\kafka\libs\jaxb-api-2.3.1.jar;D:\GR1\kafka\libs\jersey-client-2.39.1.jar;D:\GR1\kafka\libs\jersey-common-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-2.39.1.jar;D:\GR1\kafka\libs\jersey-container-servlet-core-2.39.1.jar;D:\GR1\kafka\libs\jersey-hk2-2.39.1.jar;D:\GR1\kafka\libs\jersey-server-2.39.1.jar;D:\GR1\kafka\libs\jetty-client-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-continuation-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-http-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-io-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-security-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-server-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlet-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-servlets-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jetty-util-ajax-9.4.56.v20240826.jar;D:\GR1\kafka\libs\jline-3.25.1.jar;D:\GR1\kafka\libs\jopt-simple-5.0.4.jar;D:\GR1\kafka\libs\jose4j-0.9.4.jar;D:\GR1\kafka\libs\jsr305-3.0.2.jar;D:\GR1\kafka\libs\kafka-clients-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka-group-coordinator-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-metadata-3.9.0.jar;D:\GR1\kafka\libs\kafka-raft-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-3.9.0.jar;D:\GR1\kafka\libs\kafka-server-common-3.9.0.jar;D:\GR1\kafka\libs\kafka-shell-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-3.9.0.jar;D:\GR1\kafka\libs\kafka-storage-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-examples-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-scala_2.13-3.9.0.jar;D:\GR1\kafka\libs\kafka-streams-test-utils-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-3.9.0.jar;D:\GR1\kafka\libs\kafka-tools-api-3.9.0.jar;D:\GR1\kafka\libs\kafka-transaction-coordinator-3.9.0.jar;D:\GR1\kafka\libs\kafka_2.13-3.9.0.jar;D:\GR1\kafka\libs\lz4-java-1.8.0.jar;D:\GR1\kafka\libs\maven-artifact-3.9.6.jar;D:\GR1\kafka\libs\metrics-core-2.2.0.jar;D:\GR1\kafka\libs\metrics-core-4.1.12.1.jar;D:\GR1\kafka\libs\netty-buffer-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-codec-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-common-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-handler-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-resolver-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-classes-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-epoll-4.1.111.Final.jar;D:\GR1\kafka\libs\netty-transport-native-unix-common-4.1.111.Final.jar;D:\GR1\kafka\libs\opentelemetry-proto-1.0.0-alpha.jar;D:\GR1\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\GR1\kafka\libs\paranamer-2.8.jar;D:\GR1\kafka\libs\pcollections-4.0.1.jar;D:\GR1\kafka\libs\plexus-utils-3.5.1.jar;D:\GR1\kafka\libs\protobuf-java-3.25.5.jar;D:\GR1\kafka\libs\reflections-0.10.2.jar;D:\GR1\kafka\libs\reload4j-1.2.25.jar;D:\GR1\kafka\libs\rocksdbjni-7.9.2.jar;D:\GR1\kafka\libs\scala-collection-compat_2.13-2.10.0.jar;D:\GR1\kafka\libs\scala-java8-compat_2.13-1.0.2.jar;D:\GR1\kafka\libs\scala-library-2.13.14.jar;D:\GR1\kafka\libs\scala-logging_2.13-3.9.5.jar;D:\GR1\kafka\libs\scala-reflect-2.13.14.jar;D:\GR1\kafka\libs\slf4j-api-1.7.36.jar;D:\GR1\kafka\libs\slf4j-reload4j-1.7.36.jar;D:\GR1\kafka\libs\snappy-java-1.1.10.5.jar;D:\GR1\kafka\libs\swagger-annotations-2.2.8.jar;D:\GR1\kafka\libs\trogdor-3.9.0.jar;D:\GR1\kafka\libs\zookeeper-3.8.4.jar;D:\GR1\kafka\libs\zookeeper-jute-3.8.4.jar;D:\GR1\kafka\libs\zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,599] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-22\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Common Files\Oracle\Java\javapath;C:\ProgramData\Oracle\Java\javapath;C:\MinGW\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\MATLAB\R2023a\runtime\win64;C:\Program Files\MATLAB\R2023a\bin;D:\Git\cmd;C:\Program Files\nodejs\;D:\Flutter\bin;C:\Users\PC\AppData\Local\Programs\Python\Python312\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python312\;C:\Users\PC\AppData\Local\Programs\Python\Python311\Scripts\;C:\Users\PC\AppData\Local\Programs\Python\Python311\;C:\Users\PC\AppData\Local\Microsoft\WindowsApps;D:\LaTex\miktex\bin\x64\;D:\Code\.vscode\Microsoft VS Code\bin;C:\Program Files\JetBrains\IntelliJ IDEA 2023.2\bin;;C:\Users\PC\AppData\Roaming\npm;C:\Users\PC\AppData\Local\GitHubDesktop\bin;C:\Users\PC\AppData\Roaming\TinyTeX\bin\windows;. (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,600] INFO Client environment:java.io.tmpdir=C:\Users\PC\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,601] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,602] INFO Client environment:os.name=Windows 11 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,602] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,602] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,602] INFO Client environment:user.name=PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,602] INFO Client environment:user.home=C:\Users\PC (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,603] INFO Client environment:user.dir=D:\GR1\Code (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,603] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,603] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,603] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,605] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@68034211 (org.apache.zookeeper.ZooKeeper)
[2024-11-26 18:52:49,652] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2024-11-26 18:52:49,657] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:52:49,660] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:52:49,662] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:52:49,664] INFO Socket connection established, initiating session, client: /127.0.0.1:56465, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:52:49,670] INFO Creating new log file: log.13d (org.apache.zookeeper.server.persistence.FileTxnLog)
[2024-11-26 18:52:49,675] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100006645f90000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2024-11-26 18:52:49,678] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2024-11-26 18:52:49,837] INFO Cluster ID = saHQzoN5SFCMgJPSmTinsQ (kafka.server.KafkaServer)
[2024-11-26 18:52:49,882] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.gzip.level = -1
	compression.lz4.level = 9
	compression.type = producer
	compression.zstd.level = 3
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.bootstrap.servers = []
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	eligible.leader.replicas.enable = false
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.migration.policy = disabled
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.append.linger.ms = 10
	group.coordinator.new.enable = false
	group.coordinator.rebalance.protocols = [classic]
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	group.share.delivery.count.limit = 5
	group.share.enable = false
	group.share.heartbeat.interval.ms = 5000
	group.share.max.groups = 10
	group.share.max.heartbeat.interval.ms = 15000
	group.share.max.record.lock.duration.ms = 60000
	group.share.max.session.timeout.ms = 60000
	group.share.max.size = 200
	group.share.min.heartbeat.interval.ms = 5000
	group.share.min.record.lock.duration.ms = 15000
	group.share.min.session.timeout.ms = 45000
	group.share.partition.max.record.locks = 200
	group.share.record.lock.duration.ms = 30000
	group.share.session.timeout.ms = 45000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.9-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dir.failure.timeout.ms = 30000
	log.dirs = D:/GR1/kafka/tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.initial.task.delay.ms = 30000
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	max.request.partition.size.limit = 2000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 3
	num.recovery.threads.per.data.dir = 3
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.fetch.max.wait.ms = 500
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.copier.thread.pool.size = -1
	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
	remote.log.manager.copy.quota.window.num = 11
	remote.log.manager.copy.quota.window.size.seconds = 1
	remote.log.manager.expiration.thread.pool.size = -1
	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
	remote.log.manager.fetch.quota.window.num = 11
	remote.log.manager.fetch.quota.window.size.seconds = 1
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.allow.dn.changes = false
	ssl.allow.san.changes = false
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	telemetry.max.bytes = 1048576
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unclean.leader.election.interval.ms = 300000
	unstable.api.versions.enable = false
	unstable.feature.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.metadata.migration.min.batch.size = 200
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-11-26 18:52:49,936] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:52:49,937] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:52:49,937] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:52:49,939] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-11-26 18:52:49,973] INFO Loading logs from log dirs ArrayBuffer(D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:52:50,000] INFO Skipping recovery of 3 logs from D:\GR1\kafka\tmp\kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2024-11-26 18:52:50,064] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 6655 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,070] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,071] INFO [ProducerStateManager partition=data_real_time-2] Loading producer state from snapshot file 'SnapshotFile(offset=6655, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2\00000000000000006655.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:52:50,071] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5990 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,085] INFO [LogLoader partition=data_real_time-2, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 14ms for snapshot load and 0ms for segment recovery from offset 6655 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,089] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Loading producer state till offset 5182 with message format version 2 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,090] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,089] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,121] INFO [ProducerStateManager partition=data_real_time-0] Loading producer state from snapshot file 'SnapshotFile(offset=5990, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0\00000000000000005990.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:52:50,121] INFO [ProducerStateManager partition=data_real_time-1] Loading producer state from snapshot file 'SnapshotFile(offset=5182, file=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1\00000000000000005182.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-11-26 18:52:50,146] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-2, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6655) with 1 segments, local-log-start-offset 0 and log-end-offset 6655 in 134ms (1/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:52:50,122] INFO [LogLoader partition=data_real_time-0, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 5990 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,148] INFO [LogLoader partition=data_real_time-1, dir=D:\GR1\kafka\tmp\kafka-logs] Producer state recovery took 27ms for snapshot load and 0ms for segment recovery from offset 5182 (kafka.log.UnifiedLog$)
[2024-11-26 18:52:50,160] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-0, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5990) with 1 segments, local-log-start-offset 0 and log-end-offset 5990 in 156ms (2/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:52:50,164] INFO Completed load of Log(dir=D:\GR1\kafka\tmp\kafka-logs\data_real_time-1, topicId=roy-SSlcSyaAHnye49BBtw, topic=data_real_time, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=5182) with 1 segments, local-log-start-offset 0 and log-end-offset 5182 in 160ms (3/3 completed in D:\GR1\kafka\tmp\kafka-logs) (kafka.log.LogManager)
[2024-11-26 18:52:50,184] INFO Loaded 3 logs in 209ms (kafka.log.LogManager)
[2024-11-26 18:52:50,195] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-11-26 18:52:50,196] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-11-26 18:52:50,289] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-11-26 18:52:50,299] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2024-11-26 18:52:50,312] INFO [MetadataCache brokerId=0] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)
[2024-11-26 18:52:50,330] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:52:50,560] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-11-26 18:52:50,580] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2024-11-26 18:52:50,587] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:52:50,609] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,609] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,610] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,610] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,611] INFO [ExpirationReaper-0-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,622] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-11-26 18:52:50,629] INFO [AddPartitionsToTxnSenderThread-0]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-11-26 18:52:50,701] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2024-11-26 18:52:50,728] INFO Stat of the created znode at /brokers/ids/0 is: 332,332,1732621970712,1732621970712,1,0,0,72058033298538496,214,0,332
 (kafka.zk.KafkaZkClient)
[2024-11-26 18:52:50,729] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://LAPTOP-RVLAKEFN:9092, czxid (broker epoch): 332 (kafka.zk.KafkaZkClient)
[2024-11-26 18:52:50,783] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,809] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,809] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,847] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:52:50,854] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-11-26 18:52:50,875] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:52:50,878] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-11-26 18:52:50,880] INFO [TxnMarkerSenderThread-0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-11-26 18:52:50,938] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-11-26 18:52:50,967] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2024-11-26 18:52:50,996] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Enabling request processing. (kafka.network.SocketServer)
[2024-11-26 18:52:50,998] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-11-26 18:52:51,001] INFO [KafkaServer id=0] Start processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:52:51,002] INFO [KafkaServer id=0] End processing authorizer futures (kafka.server.KafkaServer)
[2024-11-26 18:52:51,002] INFO [KafkaServer id=0] Start processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:52:51,002] INFO [KafkaServer id=0] End processing enable request processing future (kafka.server.KafkaServer)
[2024-11-26 18:52:51,008] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:52:51,009] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:52:51,010] INFO Kafka startTimeMs: 1732621971002 (org.apache.kafka.common.utils.AppInfoParser)
[2024-11-26 18:52:51,011] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2024-11-26 18:52:51,490] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(data_real_time-0, data_real_time-1, data_real_time-2) (kafka.server.ReplicaFetcherManager)
[2024-11-26 18:52:51,508] INFO [Partition data_real_time-0 broker=0] Log loaded for partition data_real_time-0 with initial high watermark 5990 (kafka.cluster.Partition)
[2024-11-26 18:52:51,517] INFO [Partition data_real_time-1 broker=0] Log loaded for partition data_real_time-1 with initial high watermark 5182 (kafka.cluster.Partition)
[2024-11-26 18:52:51,518] INFO [Partition data_real_time-2 broker=0] Log loaded for partition data_real_time-2 with initial high watermark 6655 (kafka.cluster.Partition)
[2024-11-26 18:52:51,543] INFO [zk-broker-0-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:52:51,569] INFO [zk-broker-0-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node LAPTOP-RVLAKEFN:9092 (id: 0 rack: null) (kafka.server.NodeToControllerRequestThread)
[2024-11-26 18:53:14,213] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:15,215] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:16,224] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:17,231] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:18,239] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:19,208] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:20,259] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:21,267] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:22,279] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:23,285] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:24,213] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:25,300] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:26,307] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:27,313] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:28,363] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:29,228] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:30,377] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:31,386] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:32,396] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:33,401] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:34,232] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:35,403] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:36,404] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:37,414] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:38,427] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:39,243] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:40,442] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:41,449] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:42,452] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:43,459] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:44,248] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:45,475] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:46,481] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:47,491] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:48,509] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:49,262] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:50,585] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:51,599] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:52,607] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:53,615] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:54,304] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:55,635] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:56,637] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:57,642] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:58,656] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:53:59,308] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:00,688] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:01,699] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:02,706] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:03,714] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:04,320] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:05,734] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:06,737] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:07,745] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:08,753] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
[2024-11-26 18:54:09,326] INFO [Admin Manager on Broker 0]: Error processing create topic request CreatableTopic(name='__consumer_offsets', numPartitions=50, replicationFactor=3, assignments=[], configs=[CreatableTopicConfig(name='compression.type', value='producer'), CreatableTopicConfig(name='cleanup.policy', value='compact'), CreatableTopicConfig(name='segment.bytes', value='104857600')]) (kafka.server.ZkAdminManager)
org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
